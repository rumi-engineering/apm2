rfc_risks_and_open_questions:
  risks:
    - id: RISK-001
      title: "High false positive rate blocks legitimate PRs"
      severity: HIGH
      likelihood: MEDIUM
      description: |
        AAT detectors may flag valid code patterns (e.g., legitimate
        config conditionals, stable UUIDs in test fixtures) as gaming.
        This could block otherwise correct PRs during shadow mode or
        soft enforcement, eroding developer trust.
      impact: |
        - Blocked PRs cause merge delays
        - Developers lose confidence in tooling
        - Waiver system becomes overloaded (>5% of PRs)
        - May trigger rollback of AAT enforcement
      mitigation: |
        - Shadow mode rollout (1 week): AAT runs but does not block
          to identify false positive patterns before enforcement
        - Easy waiver process: 15-minute grant flow for AUTH_SECURITY
        - Continuous tuning: Weekly review of detection patterns
        - Machine learning adjustments: Feedback loop to reduce FP rate
        - Target: < 5% of legitimate PRs trigger detections
        - Metrics: Track override rate as early warning
      owner: AUTH_PRODUCT
      monitoring:
        - "False positive rate tracking per detector"
        - "Waiver request rate and approval lag"
        - "Developer sentiment via survey (weekly during rollout)"
      escalation: |
        - If FP rate > 15% during shadow mode: extend shadow mode 1 week
        - If FP rate > 20% during soft enforcement: rollback to shadow mode
        - If FP rate > 10% during full enforcement: escalate to AUTH_PRODUCT

    - id: RISK-002
      title: "LLM hypothesis quality varies"
      severity: MEDIUM
      likelihood: MEDIUM
      description: |
        AAT relies on LLM-generated hypotheses to drive testing decisions.
        LLM output is non-deterministic and quality varies based on:
        - PR description clarity
        - LLM model version
        - Prompt engineering changes
        Quality degradation could yield weak hypotheses that don't catch
        real bugs or leave undiscovered gaming patterns.
      impact: |
        - Weak hypotheses miss actual PR claims
        - AAT becomes insufficient validation mechanism
        - Escalates false negatives (gaming goes undetected)
        - Undermines confidence in evidence bundle
      mitigation: |
        - Validation layer: Hypotheses must satisfy schema criteria
          (testable, distinct, error-handling coverage)
        - Retry with validation: Regenerate if schema validation fails
        - Manual review gate: AUTH_ARCHITECTURE reviews hypotheses for
          PRs with high-risk changes (security, core libraries)
        - Metrics dashboard: Track hypothesis generation success rate
        - Fallback: If LLM generation fails, require human-written
          hypotheses in PR description
      owner: AUTH_ARCHITECTURE
      monitoring:
        - "Hypothesis validation success rate"
        - "Manual review coverage and findings"
        - "Hypothesis quality metric changes"
      escalation: |
        - If validation fail rate > 20%: require human-written hypotheses
        - If quality degradation detected: escalate to model team
        - If LLM service unavailable: pause AAT, enable waiver path

    - id: RISK-003
      title: "Evidence script execution security"
      severity: HIGH
      likelihood: LOW
      description: |
        Evidence scripts are arbitrary code submitted in PRs. Even with
        sandboxing, execution risks include:
        - Resource exhaustion (infinite loops, memory bombs)
        - Privilege escalation in sandbox
        - Secrets leakage to logs
        - Post-execution cleanup failures
        - Denial of service via long execution times
      impact: |
        - Compromised CI/CD environment
        - Leaked credentials in logs/artifacts
        - CI/CD degradation or outage
        - AAT service unavailability
      mitigation: |
        - Container sandboxing: Run scripts in isolated Docker containers
          with read-only root filesystem, no network, no secrets access
        - Resource limits: CPU timeout 5 minutes, memory limit 2GB
        - Process limits: Max 100 child processes
        - Filesystem limits: 1GB output directory, quota enforcement
        - Secrets redaction: Automated redaction of env vars in logs
        - Network isolation: No access to internal networks or services
        - Exit handler: Force cleanup on timeout via SIGKILL
        - Audit: Log all script executions with hash, inputs, outputs
        - Attestation: Script hash must match PR description
      owner: AUTH_SECURITY
      monitoring:
        - "Sandbox escape attempts detected"
        - "Resource limit enforcement metrics"
        - "Execution timeouts and cleanup failures"
      escalation: |
        - If escape attempt detected: immediate investigation + disclosure
        - If cleanup failures > 1%: halt script execution
        - If timeouts > 10%: review script complexity with authors

    - id: RISK-004
      title: "AAT becomes bottleneck for development velocity"
      severity: MEDIUM
      likelihood: MEDIUM
      description: |
        AAT adds significant latency to PR merge workflow:
        - PR description parsing: 100ms
        - Hypothesis generation: 30 seconds (LLM call)
        - Anti-gaming analysis: 500ms - 5 seconds
        - Evidence script execution: 1-5 minutes
        - Evidence bundle generation: 1 minute
        Total: 2-7 minutes per PR. If 50+ PRs/day, this becomes a
        bottleneck, especially if execution capacity is limited.
      impact: |
        - PR merge latency increases 2-7 minutes
        - Developers experience slow feedback loop
        - Queue buildup during peak hours
        - May trigger soft enforcement rollback
      mitigation: |
        - Parallel execution: Run anti-gaming and hypothesis generation
          in parallel, not sequentially (target: 2x speedup)
        - Caching: Cache hypothesis generation for identical PR sections
          across similar PRs (semantic hashing)
        - Fast path: Skip LLM if PR description matches known patterns
          (simple code changes, low-risk files)
        - Distributed execution: Horizontal scaling with task queue
        - Lazy evaluation: Defer evidence script execution to background
          if PR passes other gates
        - Metrics: p50/p95/p99 latency monitoring per stage
        - Target: p95 latency < 2 minutes (LLM call budgeted at 90%)
      owner: AUTH_ARCHITECTURE
      monitoring:
        - "AAT execution time percentiles per stage"
        - "Hypothesis cache hit rate"
        - "Queue depth and wait times"
        - "Resource utilization (CPU, memory)"
      escalation: |
        - If p95 latency > 3 minutes: investigate bottlenecks
        - If queue depth > 20 PRs: add execution capacity
        - If developers complain about latency: prioritize optimization

    - id: RISK-005
      title: "Waiver system misuse or expired waivers cause confusion"
      severity: MEDIUM
      likelihood: LOW
      description: |
        Waivers expire after 30 days and must be re-evaluated. If
        expired waivers block PRs without clear messaging, or if
        granting authorities abuse waiver grants, system trust erodes.
      impact: |
        - Unexpected PR blocks after waiver expiry
        - Developer confusion about waiver status
        - Over-reliance on waivers masks systemic issues
      mitigation: |
        - Clear expiry messaging: PR comment warns of expiry 7 days before
        - Waiver audit: Monthly review of all active waivers with AUTH_PRODUCT
        - Rate limiting: No more than 5% of PRs under waiver at any time
        - Automatic renewal denial: Force re-evaluation after expiry,
          no automatic renewal
        - Waiver metrics: Track waiver rate by feature/author to identify
          patterns
      owner: AUTH_PRODUCT
      monitoring:
        - "Active waiver count and expiry dates"
        - "Waiver grant rate by authority"
        - "Waiver abuse indicators"
      escalation: |
        - If waiver rate > 5%: escalate to AUTH_PRODUCT for investigation
        - If waiver grant times > 8 hours: investigate bottleneck

  open_questions:
    - id: OQ-001
      question: "Should AAT run on draft PRs?"
      status: RESOLVED
      resolution: |
        No, only on PRs marked ready-for-review.

        Rationale:
        - Draft PRs are work-in-progress and don't represent submission state
        - Early feedback on drafts is not value-add if code changes before ready
        - Evidence script execution on incomplete code may be wasteful
        - Reduces load on AAT infrastructure

        Implementation:
        - GitHub API webhook checks PR.draft flag
        - Only trigger AAT when PR transitions to ready-for-review
        - If developer marks PR back to draft, AAT remains but doesn't block
        - Manual override: Comments with "aat run" trigger on-demand execution
      owner: AUTH_ARCHITECTURE
      affected_requirements:
        - REQ-0002

    - id: OQ-002
      question: "How to handle flaky (non-deterministic) evidence scripts?"
      status: RESOLVED
      resolution: |
        Retry up to 3 times with identical seed/environment, require
        determinism proof.

        Rationale:
        - Flaky tests indicate poor evidence script quality
        - Cannot trust hypothesis verification if test is non-deterministic
        - Three attempts balances discovery vs. latency (3 retries = 15min worst case)
        - Determinism requirement forces authors to eliminate randomness

        Implementation:
        - First execution: Run script as-is, record seed/rng state
        - If fails: Retry with identical seed (exported environment)
        - After 3 retries: Mark as flaky, emit high-severity detection
        - Require fix: PR author must make script deterministic (seed-based)
        - Documentation: PR must document why non-determinism exists
        - Waiver: If unavoidable (e.g., system-dependent), require AUTH_SECURITY waiver

        Determinism proof:
        - Same seed -> same output (verified across 3 runs)
        - Execution log includes seed and RNG stream hash
        - Script must not use system time, file mtime, or random()
      owner: AUTH_ARCHITECTURE
      affected_requirements:
        - REQ-0009

    - id: OQ-003
      question: "How should AAT be invoked from Claude Code and other agents?"
      status: RESOLVED
      resolution: |
        Via Claude Code CLI with xtask integration: cargo xtask aat <PR_URL>
        For API-based invocation: Direct API calls to AAT service with
        PR URL and optional override flags.

        Rationale:
        - xtask provides standard interface across all agents
        - CLI is easiest for agent invocation without direct API knowledge
        - API path supports programmatic integration in GitHub Actions
        - Both paths use same underlying AAT engine

        Implementation:
        - Invocation path 1 (Claude Code):
          Command: cargo xtask aat https://github.com/owner/repo/pull/123
          Output: Event stream to stdout (NDJSON)
          Exit code: 0 for pass, non-zero for fail/gaming

        - Invocation path 2 (GitHub Actions):
          Call: POST /api/v1/aat/evaluate with PR URL in payload
          Response: AsyncTaskId
          Poll: GET /api/v1/aat/tasks/{id} for status
          Webhook: Optional callback to PR comment with results

        - Invocation path 3 (Direct Python/Bash):
          Option: Import AAT as library (apm2-aat crate) for programmatic use
          Stability: Semver versioning guarantees for library API

        Status check integration:
        - xtask automatically creates/updates GitHub status check
        - AAT service handles status check logic for API path
        - Status name: "aat/acceptance" (blocking), "aat/quality" (optional)
      owner: AUTH_ARCHITECTURE
      affected_requirements:
        - REQ-0002
        - REQ-0007

    - id: OQ-004
      question: "Should evidence bundles be retained permanently or garbage-collected?"
      status: RESOLVED
      resolution: |
        Retain for 90 days per PR, then delete. Archive to cold storage
        on request by legal/security.

        Rationale:
        - Permanent retention inflates storage costs
        - 90 days covers typical regression debugging window
        - Legal/security can request archive for specific PRs
        - Reduces data retention compliance burden

        Implementation:
        - Default TTL: 90 days from PR merge
        - Storage tiers: Hot (90 days), Warm (archived request)
        - Deletion: Automated via retention policy, with audit log
      owner: AUTH_RELIABILITY

    - id: OQ-005
      question: "Who can approve waivers and with what authority?"
      status: RESOLVED
      resolution: |
        AUTH_SECURITY can approve anti-gaming waivers for up to 30 days.
        AUTH_PRODUCT can override any waiver decision.
        AUTH_ARCHITECTURE can approve hypothesis quality waivers.

        Rationale:
        - Separation of duties: Different authorities for different risks
        - Time-limited waivers: 30-day max reduces long-term workarounds
        - Audit trail: All waiver decisions logged
        - Escalation path: AUTH_PRODUCT has final say for conflicts

        Implementation:
        - Waiver request triggered by PR comment: @aat-waiver <reason>
        - System routes to appropriate authority based on rejection reason
        - Authority reviews comment thread and PR code
        - Decision: aat-waiver approve/deny <duration>
        - Audit log: Automatic entry with approver, reason, duration
      owner: AUTH_SECURITY
      affected_requirements:
        - REQ-0010

    - id: OQ-006
      question: "Should AAT results affect developer reputation or scoring?"
      status: RESOLVED
      resolution: |
        No. AAT is a merge gate, not a performance metric.
        Gaming detections are not attribution issues; they indicate
        process gaps, not incompetence.

        Rationale:
        - AAT should drive process improvement, not blame
        - Detections may be false positives (mitigated by shadow mode)
        - Not all PRs require evidence scripts (depends on change type)
        - Developer autonomy and trust matter

        Implementation:
        - No "gamer" leaderboards or reputation tracking
        - Gaming detections handled by process review (not personnel review)
        - Metrics dashboard: Aggregate trends only
        - Privacy: Individual PR results shared only with PR author + reviewers
      owner: AUTH_PRODUCT
