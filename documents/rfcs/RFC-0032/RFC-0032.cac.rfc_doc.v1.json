{
  "schema": "cac.rfc_doc.v1",
  "schema_version": "1.0.0",
  "kind": "rfc.document",
  "meta": {
    "id": "RFC-0032",
    "title": "Kernel-Native Forge Admission Cycle vNext",
    "stable_id": "dcp://apm2.dev/rfc/RFC-0032",
    "labels": [
      "fac",
      "kernel",
      "ledger",
      "cas",
      "work_graph",
      "work_context",
      "pulse",
      "daemon",
      "cli",
      "migration",
      "implementation_grade"
    ],
    "relationships": [
      {
        "kind": "REFERENCES",
        "ref": "documents/rfcs/RFC-0018/TECHNICAL_PROPOSAL_WORKOBJECT_LEDGER_CUTOVER.md",
        "note": "WorkObject ledger cutover proposal; authority/boundary contract; parity mapping."
      },
      {
        "kind": "REFERENCES",
        "ref": "documents/rfcs/RFC-0019/AUTONOMOUS_FORGE_ADMISSION_CYCLE.md",
        "note": "FAC boundary discipline; idempotent actuation; digest-first interfaces."
      },
      {
        "kind": "AFFECTS",
        "ref": "crates/apm2-core",
        "note": "Ledger storage/read-mode unification; reducers; evidence categories; schema registry; parity gate plumbing."
      },
      {
        "kind": "AFFECTS",
        "ref": "crates/apm2-daemon",
        "note": "Protocol handlers; CAS integration; projections; work loop manager; pulse publisher/topic derivation; merge executor."
      },
      {
        "kind": "AFFECTS",
        "ref": "crates/apm2-cli",
        "note": "`apm2 fac push` work_id binding + context markers; `apm2 work open/doctor`; pulse wait integration."
      },
      {
        "kind": "AFFECTS",
        "ref": "proto/kernel_events.proto",
        "note": "WorkGraphEvent; session pin extensions; kernel typed events payload convergence."
      },
      {
        "kind": "AFFECTS",
        "ref": "proto/apm2d_runtime_v1.proto",
        "note": "OpenWork, ClaimWorkV2, work graph RPCs, context/profile publishing, PR association, pulse wait integration."
      },
      {
        "kind": "AFFECTS",
        "ref": "documents/rfcs/*",
        "note": "New CAC representation file for RFC-0032; aligns with CAC RFC doc schema."
      }
    ],
    "provenance": {
      "actor_id": "APM2-DOC-GOV",
      "work_id": "RFC-0032",
      "notes": "Generated from final Markdown RFC into cac.rfc_doc.v1 format."
    }
  },
  "payload": {
    "root": {
      "type": "rfc",
      "title": "RFC-0032: Kernel-Native Forge Admission Cycle vNext",
      "children": [
        {
          "type": "section",
          "title": "0. Reader guide: terms, identifiers, and event families",
          "children": [
            {
              "type": "section",
              "title": "0.1 Terminology",
              "children": [],
              "data": {
                "heading_level": 3
              },
              "body": "* **Work**: a state machine instance reduced by `apm2-core` (`crates/apm2-core/src/work/*`).\n* **WorkSpec**: immutable, content-addressed \"what is this work?\" document stored in CAS and\n  referenced by `WorkOpened.spec_snapshot_hash`.\n* **WorkObject**: a *projection / unified view* of work + graph + context (see RFC-0018), not an\n  additional truth source.\n* **Work graph**: directed dependency edges between works (this RFC introduces canonical events +\n  projections for mutable edges and waivers).\n* **Work context stream**: append-only, CAS-backed notes/artifacts anchored in the ledger via\n  `evidence.published`.\n* **Episode / Session**: runtime execution units spawned via `SpawnEpisode` and tracked via session\n  events. Session reduction exists in `crates/apm2-core/src/session/*`.\n* **Lease**: daemon-issued capability binding a role+actor to a work. Today it is required for\n  spawning episodes (see `handle_spawn_episode` in `crates/apm2-daemon/src/protocol/dispatch.rs`).\n* **Projection**: derived SQLite tables/materialized views that are fully replayable from\n  (ledger + CAS). These are caches, never authority."
            },
            {
              "type": "section",
              "title": "0.2 Identifier formats (repo reality today)",
              "children": [],
              "data": {
                "heading_level": 3
              },
              "body": "The daemon currently generates identifiers as UUIDv4 strings (not timestamps):\n\n* `work_id`: `W-<uuid_v4>` (`generate_work_id` in `crates/apm2-daemon/src/protocol/dispatch.rs`)\n* `lease_id`: `L-<uuid_v4>` (`generate_lease_id` in the same module)\n* `session_id`: `S-<uuid_v4>` (created in `handle_spawn_episode`)\n\nThis RFC keeps these formats through cutover unless a future identity RFC changes them."
            },
            {
              "type": "section",
              "title": "0.3 Event families and payload encodings",
              "children": [],
              "data": {
                "heading_level": 3
              },
              "body": "APM2 currently has **three** event \"families\" that refer to the same semantic facts:\n\n| Family | Example `event_type` | Where it exists today | Payload encoding | Primary consumer |\n|---|---|---|---|---|\n| Legacy signed (underscore) | `work_claimed`, `session_started`, `changeset_published` | daemon `ledger_events` + WorkRegistry | canonical JSON bytes, Ed25519 signature over `domain_prefix || payload` (`crates/apm2-daemon/src/ledger.rs`) | daemon projections, legacy CLI flows |\n| Reducer-domain (dot) | `work.opened`, `work.transitioned`, `session.started`, `evidence.published` | core reducer world | protobuf bytes (`WorkEvent`, `SessionEvent`, `EvidenceEvent`) | `apm2-core` reducers (`work/reducer.rs`, `session/reducer.rs`) |\n| HEF/pulse typed | `WorkOpened`, `SessionStarted`, `GateLeaseIssued` | pulse/topic taxonomy + commit notifications | typed discriminant used for topic derivation (RFC-0018 `02_design_decisions.yaml`, `topic_derivation.rs`) | push-based waits, outbox fanout |\n\nTwo constraints follow immediately:\n\n* Any new event whose `event_type` starts with **`work.`** is decoded as a `WorkEvent` by\n  `WorkReducer` (`crates/apm2-core/src/work/reducer.rs`). Introducing `work.*` types whose payload is\n  not a `WorkEvent` will hard-fail reduction (this is a sharp edge in the current code).\n* The repo already contains an explicit parity/convergence mapping for work lifecycle facts across\n  families (`crates/apm2-core/src/work/parity.rs`). Any bridge window must maintain parity (or\n  explicitly declare which family is being retired)."
            }
          ],
          "data": {
            "heading_level": 2
          },
          "body": "This RFC spans three partially-overlapping \"planes\" that exist in the repo today: legacy signed JSON\nevents, reducer-facing dot events, and HEF/pulse typed discriminants. The document is easy to misread\nunless we pin down vocabulary and the constraints those planes impose."
        },
        {
          "type": "section",
          "title": "1. Problem statement (grounded in current APM2)",
          "children": [],
          "data": {
            "heading_level": 2
          },
          "body": "APM2 currently has **two ledger planes** plus several “shadow truth” stores that collectively represent FAC reality:\n\n1. **Daemon legacy signed ledger** (`ledger_events` + domain-separated signatures) and **WorkRegistry** tables (`work_claims`, policy resolution JSON, etc.) in `crates/apm2-daemon/src/ledger.rs`.\n\n   * `ClaimWork` in `crates/apm2-daemon/src/protocol/dispatch.rs` **generates a new `work_id`** and persists claim metadata in WorkRegistry (SQLite), plus emits `work_claimed`/`work_transitioned` legacy events.\n   * `PublishChangeSet` similarly requires WorkRegistry to authorize and uses registry state not fully reconstructible from legacy event payloads (policy resolution details, adapter profile hash, etc.).\n\n2. **Core ledger** (`events` table + hash chaining + optional BFT wrapper) in `crates/apm2-core/src/ledger/*`.\n\n   * Today, the core ledger is frequently in `LedgerReadMode::LegacyLedgerEvents` (see `determine_read_mode`) because `ledger_events` exists and the canonical `events` table is empty.\n\n     * In this mode, `LedgerStorage::ensure_writable()` rejects canonical appends with `LedgerStorageError::LegacyModeReadOnly`.\n     * If both `ledger_events` **and** `events` contain rows, `determine_read_mode` fails fast with `LedgerReadModeError::AmbiguousSchemaState`.\n\n     This blocks forward progress: you cannot safely start writing canonical events without first eliminating the ambiguous two-ledger state.\n\n3. **FAC v0 (CLI-local) ticket/YAML truth** and `fac_review` orchestrator state:\n\n   * `apm2 fac push` is implemented via `crates/apm2-cli/src/commands/fac_review/push.rs` and still relies heavily on ticket YAML and local projections.\n\n4. **Pulse plane** exists but is **not end-to-end consistent with the actual ledger encoding**:\n\n   * `PulsePublisher` currently decodes `KernelEvent` envelopes in `pulse_outbox.rs`, while most real emitted facts today are legacy signed events and/or protobuf domain events (not the KernelEvent envelope).\n   * `topic_derivation.rs` tests currently treat event types like `\"WorkOpened\"` whereas core reducer naming uses dot prefixes (e.g. `work.opened`) and legacy uses underscores (e.g. `work_claimed`). This mismatch is not merely cosmetic: it blocks “push-based wait” from being reliable.\n\nThis fragmentation causes concrete, code-real failures:\n\n* **Implementer lifecycle isn’t closed**: daemon runs `SpawnEpisode` and records `session_started/session_terminated`, but there is no daemon-authoritative loop ensuring that an implementer attempt produces a durable terminal marker (`fac push`) and a handoff note before proceeding.\n* **Work dependencies are not first-class**: there is no authoritative, mutable work DAG. At best there are ad-hoc dependency lists (`dependency_work_ids`) in claim requests, or static `parent_work_ids` in `WorkOpened`, but no mutable edges + waivers.\n* **Work context isn’t authoritative**: handoff notes, diagnoses, reviewer findings/verdict summaries live in local files or GitHub comments, not in the kernel truth plane (ledger + CAS). Nothing can reliably replay them.\n* **Authority state is still split**: WorkRegistry holds security/authority-relevant data (policy resolution, adapter profile hashes, etc.) that is not fully derivable from ledger + CAS.\n\n---"
        },
        {
          "type": "section",
          "title": "2. Goals, non-goals, constraints",
          "children": [
            {
              "type": "section",
              "title": "2.1 Goals",
              "children": [],
              "data": {
                "heading_level": 3
              },
              "body": "G1. **Single canonical truth plane** for FAC: **Core ledger `events` table + CAS**.\nG2. **No SQLite-only authority**: all authority decisions needed for “what happens next” must be reconstructible from **(ledger events + CAS artifacts)** with deterministic projection logic.\nG3. **Work graph as first-class**: add/remove dependency edges post-open; enforce closure for claimability; support waivers without mutating history.\nG4. **Work context stream as first-class**: append-only, ledger-anchored, CAS-backed, queryable, replayable; supports handoffs, findings, diagnoses, linkouts.\nG5. **Closed implementer + reviewer loops** with daemon-governed nudging/reaping; terminal act preserved (`apm2 fac push`).\nG6. **Pulse-driven waits**: remove polling as the default “wait” mechanism; `--wait` subscribes to work-centric topics.\nG7. **Configurable operational knobs**: workspace roots, retry/nudge/backoff budgets are policy/config driven, not hard-coded in control-plane logic."
            },
            {
              "type": "section",
              "title": "2.2 Non-goals (this RFC)",
              "children": [],
              "data": {
                "heading_level": 3
              },
              "body": "NG1. Fully replacing GitHub or `fac_review` internals immediately.\nNG2. Requiring mediated tool execution (AdmissionKernel tool bridge) on the critical path. System must work in unmediated mode.\nNG3. Designing the final cryptographic actor identity model (hex key ids vs string identities) beyond what is required to make the FAC truth plane reconstructible and operational."
            },
            {
              "type": "section",
              "title": "2.3 Hard constraints (from repo reality)",
              "children": [],
              "data": {
                "heading_level": 3
              },
              "body": "C1. **Core ledger is currently often in `LedgerReadMode::LegacyLedgerEvents`**: any plan that starts writing canonical events must first eliminate the ambiguous two-ledger state (see `determine_read_mode`).\nC2. **`apm2 fac push` remains the terminal command** through cutover; no bypassing.\nC3. Daemon is the authority boundary: ledger/CAS mutations go through the daemon operator socket (UDS) unless explicitly delegated later."
            },
            {
              "type": "section",
              "title": "2.4 Drift-control guardrails (mandatory)",
              "children": [],
              "data": {
                "heading_level": 3
              },
              "body": "**Biggest risk:** implementation drift that *appears* to implement this RFC while silently diverging from the existing spine contracts already embedded in code + prior RFCs (event naming/encoding mismatches, missing authority pins, non-replayable state, \"temporary\" SQLite authority that never gets removed).\n\nThis RFC therefore declares the following drift barriers as **mandatory**, not \"nice to have\":\n\n**D1. Single source-of-truth registries (code-enforced)**\n\n1. **CAS schema ids**: every CAS JSON schema id introduced by this RFC MUST be added to\n   `crates/apm2-core/src/schema_registry/fac_schemas.rs` (and must pass its uniqueness + prefix tests; see `test_fac_schema_ids_are_unique` / `test_fac_schema_id_prefixes`).\n2. **Topic derivation coverage**: every new canonical event type introduced by this RFC MUST have a dedicated topic-derivation test in\n   `crates/apm2-daemon/src/protocol/topic_derivation.rs` that asserts the exact topic set emitted.\n3. **Parity gate integration**: if we are in a bridge window where both legacy and canonical work events exist, parity MUST be continuously checked using\n   `apm2_core::work::parity::{ParityValidator, EventFamilyPromotionGate}` (see existing production usage in `crates/apm2-daemon/src/gate/merge_executor.rs`), and promotion MUST be blocked on defects (fail-closed).\n\n**D2. Fail-closed bounded decoding (DoS + schema drift defense)**\n\nAny IPC surface that accepts user-provided bytes for CAS-backed JSON MUST:\n\n* validate schema id using `fac_schemas::validate_schema_id`,\n* decode using `fac_schemas::bounded_from_slice_with_limit` (or equivalent) with an explicit per-artifact byte limit,\n* use `#[serde(deny_unknown_fields)]` on all CAS JSON structs defined by this RFC.\n\n**D3. Preserve the existing promotion-blocking gates**\n\nThis RFC may add additional gates, but MUST NOT weaken existing ones already present in code:\n\n* **alias reconciliation promotion gate** (`crates/apm2-daemon/src/work/authority.rs`) remains promotion-blocking (fail-closed) per CTR-ALIAS-002.\n* **merge executor promotion gate** (parity/defect blocking) remains promotion-blocking.\n\n**D4. \"Done\" is measurable**\n\nEach migration phase MUST include a checklist that is both:\n\n* **machine-verifiable** (tests, invariants, metrics), and\n* **promotion-blocking** (gates deny on missing checklist items in production mode)."
            },
            {
              "type": "section",
              "title": "2.5 Alignment commitments with RFC-0018 and RFC-0019 (normative)",
              "children": [],
              "data": {
                "heading_level": 3
              },
              "body": "This RFC is vNext wiring, not a rewrite of the FAC physics. It MUST preserve the contracts already declared as mandatory in earlier RFCs and already partially embedded in code:\n\n* **RFC-0018 §6.3 Authority and Boundary Contract**: transitions/episodes/receipts require a complete set of boundary pins (lease id, permeability receipt hash, capability manifest hash, context pack hash, stop-condition hash, typed budgets). Missing pins are fail-closed and MUST be recorded as defects; best-effort is forbidden.\n* **RFC-0018 §7.3 Parity mapping**: legacy underscore work events must map cleanly to canonical reducer work events, including `previous_transition_count` monotonicity.\n* **RFC-0019 boundary discipline**: idempotent actuation, digest-first interfaces, and explicit stop/budget pins remain non-negotiable.\n\nIf a requirement is \"not yet implemented\" in this RFC's phases, the RFC MUST specify which existing event/artifact currently carries the pin and how it survives ledger unification without losing replayability.\n\n---"
            }
          ],
          "data": {
            "heading_level": 2
          }
        },
        {
          "type": "section",
          "title": "3. Canonical architecture",
          "children": [
            {
              "type": "section",
              "title": "3.1 End state overview",
              "children": [],
              "data": {
                "heading_level": 3
              },
              "body": "* **Core ledger (`apm2-core`)** stores all authoritative FAC events in the canonical `events` table.\n* **CAS (`apm2-daemon DurableCas`, implementing `apm2_core::evidence::ContentAddressedStore`)** stores immutable artifacts (work specs, context entries, evidence bundles, change sets, etc.).\n* **Projections** (SQLite tables and/or in-memory reducers) are derived from ledger + CAS and are **replayable**."
            },
            {
              "type": "section",
              "title": "3.2 Event taxonomy: classify by encoding + trust boundary, not punctuation",
              "children": [],
              "data": {
                "heading_level": 3
              },
              "body": "The repo already contains multiple event families. **Underscore vs dot is not the correct classifier**:\n\n* Some underscore events are **daemon-signed JSON** (`work_claimed`, `work_transitioned`, `session_started`, ...).\n* Many underscore events are daemon-signed JSON today (including FAC spine facts like `changeset_published` and review receipts). The corresponding domain prefixes already exist in `crates/apm2-core/src/ledger/storage.rs::domain_prefix_for_event_type`, and this RFC upgrades the canonical encoding for those facts to protobuf in the core ledger.\n* Dot-prefixed events (`work.opened`, `work.transitioned`, `evidence.published`) are reducer-facing canonical event types.\n\nThis RFC therefore uses the following taxonomy (normative):\n\n1. **DaemonSignedJson events (legacy compatibility family)**\n   * Storage (today): daemon `ledger_events` table (legacy plane).\n   * Payload: canonical JSON bytes (JCS-style determinism).\n   * Signature: daemon domain-separated signature.\n   * Examples (non-exhaustive): `work_claimed`, `work_transitioned`, `session_started`, `session_terminated`, `session_event`, `stop_flags_mutated`.\n   * Policy: these events may be ingested for replay parity during cutover, but are not the target canonical encoding. Do not extend them with new semantics.\n\n2. **ReducerProtobuf events (canonical truth for reducers)**\n   * Storage: core ledger `events` table (post-unification).\n   * Payload: protobuf bytes (e.g., `WorkEvent`, `EvidenceEvent`) with canonicalization rules already established by `apm2_core::events::Canonicalize`.\n   * Event types: `work.opened`, `work.transitioned`, `work.completed`, `work.aborted`, `evidence.published`, etc.\n   * Reducers: `apm2_core::work::WorkReducer`, `apm2_core::evidence::EvidenceReducer`, etc.\n\n3. **KernelTyped events (FAC spine facts that are not reducers' `WorkEvent`)**\n   * Storage: core ledger `events` table (post-unification).\n   * Payload encoding:\n     * **Today (repo reality):** these facts are emitted by the daemon as **signed JSON payloads** in the legacy ledger (`crates/apm2-daemon/src/ledger.rs`).\n     * **End state (this RFC):** these facts are emitted as **protobuf payloads** using the corresponding messages in `proto/kernel_events.proto` and canonicalized via `apm2_core::events::Canonicalize`.\n   * Event types: `changeset_published`, `review_receipt_recorded`, `review_blocked_recorded`, `projection_receipt_recorded`, etc.\n   * Policy: these are canonical kernel facts and MUST NOT be lumped into \"legacy intake\" just because they use underscores. During the bridge, topic derivation + projections MUST accept **both** encodings for the same `event_type` until emissions are frozen.\n\n**Key rule (bridge):** during cutover windows where both DaemonSignedJson work events and ReducerProtobuf work events exist, reducer truth MUST be checked for equivalence using\n`apm2_core::work::parity::{ParityValidator, EventFamilyPromotionGate}`, and any promotion-capable system actor MUST fail-closed on parity defects."
            },
            {
              "type": "section",
              "title": "3.3 Payload encoding + canonicalization matrix (drift barrier)",
              "children": [],
              "data": {
                "heading_level": 3
              },
              "body": "To prevent \"it worked locally\" drift, every event type introduced or relied on by this RFC MUST declare:\n\n* **payload encoding** (JSON vs protobuf),\n* **canonicalization contract** (what must be normalized before hashing/signing),\n* **topic derivation source-of-truth** (what fields are used to derive pulse topics).\n\nMinimum required declarations for this RFC:\n\n| Event type family | Example event types | Payload encoding | Canonicalization source | Topic derivation must use |\n|---|---|---:|---|---|\n| ReducerProtobuf (`WorkEvent`) | `work.opened`, `work.transitioned`, `work.completed` | protobuf | `apm2_core::events::Canonicalize` on payload structs | `work_id` extracted from decoded `WorkEvent` |\n| ReducerProtobuf (`EvidenceEvent`) | `evidence.published` | protobuf | `apm2_core::events::Canonicalize` | `work_id` from decoded `EvidencePublished.work_id` |\n| KernelTyped (bridge: JSON → protobuf) | `changeset_published`, `review_receipt_recorded` | **bridge:** JSON today; **end:** protobuf | **end state:** `apm2_core::events::Canonicalize` on the protobuf payload | `work_id` from decoded payload (bridge: JSON parse; end: protobuf decode) |\n| DaemonSignedJson | `work_claimed`, `work_transitioned` | JSON | `canonicalize_json` before signing | `work_id` from payload JSON |\n\n**Pulse implication:** `PulsePublisher` MUST NOT assume a `KernelEvent` envelope; it MUST route on `(event_type, payload_bytes)` and decode only enough to derive topics and (optionally) render doctor hints.\n\n**Normative decision:** the core ledger stores **event-type-specific payload bytes** in `events.payload` (e.g., `WorkEvent` bytes for `work.*`, `EvidenceEvent` bytes for `evidence.*`, and typed bytes for kernel facts). `KernelEvent` is treated as a *derived* representation (useful for network APIs), not the on-disk payload encoding.\n\n---"
            }
          ],
          "data": {
            "heading_level": 2
          }
        },
        {
          "type": "section",
          "title": "4. Data model (CAS documents)",
          "children": [
            {
              "type": "section",
              "title": "4.0 Schema governance + bounded decoding (mandatory)",
              "children": [],
              "data": {
                "heading_level": 3
              },
              "body": "To prevent long-lived drift between \"what the RFC intended\" and \"what got serialized in production,\" all CAS-backed JSON documents introduced here MUST:\n\n1. Carry a stable `schema` id string (e.g., `apm2.work_spec.v1`).\n2. Be registered in `crates/apm2-core/src/schema_registry/fac_schemas.rs` (schema id allowlist).\n3. Be decoded from IPC bytes using bounded deserialization:\n   * `fac_schemas::bounded_from_slice_with_limit::<T>(bytes, limit)`\n   * `#[serde(deny_unknown_fields)]` on the struct `T`.\n4. Define an explicit maximum size per artifact (fail-closed).\n\nHard caps (normative; fail-closed):\n\n* WorkSpec: **≤ 256 KiB**\n* WorkLoopProfile: **≤ 64 KiB**\n* WorkContextEntry: **≤ 256 KiB**\n* WorkAuthorityBindings: **≤ 256 KiB**\n\n**Hashing rule:** the daemon MUST canonicalize the JSON bytes first and store the canonical bytes in CAS (the hash is of canonical bytes). The daemon MUST NOT hash/store raw non-canonical input bytes."
            },
            {
              "type": "section",
              "title": "4.0.1 Deterministic IDs for idempotent evidence anchors (mandatory)",
              "children": [],
              "data": {
                "heading_level": 3
              },
              "body": "Several RPCs in this RFC are *idempotent* and anchor CAS artifacts via `evidence.published`. To make idempotency implementable without \"read-before-write\" races, the daemon MUST generate **deterministic identifiers** for:\n\n* `entry_id` (for `WorkContextEntry`)\n* `evidence_id` (for the anchoring `EvidencePublished`)\n* optional `edge_id` (when callers do not supply one)\n\n**Rule:** when an RPC defines idempotency on `(work_id, kind, dedupe_key)` (or `(work_id, dedupe_key)`), the daemon MUST deterministically derive:\n\n* `entry_id` and `evidence_id` from `(category, work_id, kind, dedupe_key)`\n* using BLAKE3 over canonical UTF-8 bytes, and a stable prefix.\n\nRecommended format (normative prefixes; exact base encoding is an implementation detail):\n\n* `WorkContextEntry`:\n  * `entry_id = \"CTX-\" + blake3(\"WORK_CONTEXT_ENTRY\" || work_id || kind || dedupe_key)`\n  * `evidence_id = entry_id`\n* `WorkLoopProfile`:\n  * `evidence_id = \"WLP-\" + blake3(\"WORK_LOOP_PROFILE\" || work_id || dedupe_key)`\n* `WorkAuthorityBindings`:\n  * `evidence_id = \"WAB-\" + blake3(\"WORK_AUTHORITY_BINDINGS\" || work_id || role || lease_id)`\n* `WorkEdge` (when callers do not supply `edge_id`):\n  * `edge_id = \"EDGE-\" + blake3(\"WORK_EDGE\" || from_work_id || to_work_id || edge_type || dedupe_key)`\n\n**Fail-closed:** if `dedupe_key` is required by the RPC, empty `dedupe_key` MUST be rejected."
            },
            {
              "type": "section",
              "title": "4.1 WorkSpec: `apm2.work_spec.v1` (immutable)",
              "children": [],
              "data": {
                "heading_level": 3
              },
              "body": "Stored in CAS; referenced by `WorkOpened.spec_snapshot_hash` (bytes).\n\nThis RFC **aligns WorkSpec with the existing work cutover proposal (RFC-0018)**: WorkSpec is “what the work is,” not “what attempts happened.”\n\n```json\n{\n  \"schema\": \"apm2.work_spec.v1\",\n  \"work_id\": \"W-<uuid>\",\n  \"ticket_alias\": \"TCK-00606\",\n  \"title\": \"Make fac push emit terminal markers and bind work_id\",\n  \"summary\": \"Kernel-native FAC push integration; add context markers; wire PR association.\",\n  \"work_type\": \"TICKET\",\n  \"fac\": { \"cycle\": \"forge_admission\" },\n  \"repo\": {\n    \"owner\": \"openai\",\n    \"name\": \"apm2\",\n    \"remote\": \"origin\",\n    \"default_branch\": \"main\"\n  },\n  \"touch_set\": {\n    \"paths\": [\"crates/apm2-cli/\", \"crates/apm2-daemon/\"],\n    \"labels\": [\"cli\", \"daemon\", \"fac\"]\n  },\n  \"requirements\": [\"REQ-HEF-0013\", \"REQ-0010\"],\n  \"metadata\": {\n    \"source\": \"ticket_yaml_import\",\n    \"ticket_path\": \"documents/work/tickets/TCK-00606.yaml\",\n    \"ticket_sha256\": \"…\"\n  }\n}\n```\n\n**Important correction vs the earlier draft:**\nDo **not** require \"ticket id becomes `work_id`.\" The codebase already has an explicit alias reconciliation design (`apm2_core::events::alias_reconcile`) and even an alias reconciliation gate stub in `handle_spawn_episode`. Use it. Ticket IDs are aliases, not canonical ids.\n\n**WorkType constraint (repo-aligned):**\n`work_type` MUST be one of the string forms accepted by `apm2_core::work::WorkType` (`TICKET`, `PRD_REFINEMENT`, `RFC_REFINEMENT`, `REVIEW`). If FAC needs additional sub-typing (\"forge admission\"), carry it as a WorkSpec facet (e.g., `fac.cycle`) rather than changing the reducer's WorkType without a dedicated RFC."
            },
            {
              "type": "section",
              "title": "4.2 WorkLoopProfile: `apm2.work_loop_profile.v1` (mutable policy/config knobs)",
              "children": [],
              "data": {
                "heading_level": 3
              },
              "body": "Stored in CAS; referenced by claim/session dispatch events (see §5, §6). This is operational tuning, **not** privilege escalation.\n\n**Immutability note:** CAS documents are immutable; \"mutable\" here means \"a newer profile hash can be published and selected.\" The RFC MUST specify how selection occurs (event + projection), not imply in-place mutation.\n\n**Mutability note (important):** CAS is immutable. \"Mutable\" here means:\npublish a new profile document + anchor it in the ledger, and treat \"latest anchored profile\" as active\nin projections. See §6.6 `PublishWorkLoopProfile`.\n\n```json\n{\n  \"schema\": \"apm2.work_loop_profile.v1\",\n  \"work_id\": \"…\",\n  \"workspace\": {\n    \"strategy\": \"git_worktree\",\n    \"root\": \"~/.apm2/worktrees\",\n    \"reuse_per_work\": true,\n    \"cleanup_on_complete\": true\n  },\n  \"implementer\": {\n    \"nudge_policy\": { \"max_nudges\": 50, \"backoff_seconds\": [30, 120, 600] },\n    \"retry_policy\": { \"git_apply_max_retries\": 25 }\n  },\n  \"reviewer\": {\n    \"nudge_policy\": { \"max_nudges\": 50, \"backoff_seconds\": [60, 300, 900] }\n  }\n}\n```\n\n**Security rule:** WorkLoopProfile cannot override the role spec / capability manifest / adapter profile constraints resolved by policy (those are already validated in `handle_spawn_episode` today via hashes)."
            },
            {
              "type": "section",
              "title": "4.3 WorkContextEntry: `apm2.work_context_entry.v1` (immutable, append-only stream)",
              "children": [],
              "data": {
                "heading_level": 3
              },
              "body": "Stored in CAS; anchored by a ledger event (`evidence.published` with category `WORK_CONTEXT_ENTRY`).\n\n```json\n{\n  \"schema\": \"apm2.work_context_entry.v1\",\n  \"work_id\": \"…\",\n  \"entry_id\": \"CTX-<blake3>\",\n  \"kind\": \"HANDOFF_NOTE\",\n  \"dedupe_key\": \"session:S-…\",\n  \"source_session_id\": \"S-…\",\n  \"actor_id\": \"actor:uid:…:gid:…\",\n  \"created_at_ns\": 0,\n  \"body\": {\n    \"format\": \"markdown\",\n    \"text\": \"Summary of changes, risks, how to review…\"\n  },\n  \"linkouts\": [\n    { \"kind\": \"PR\", \"url\": \"…\" },\n    { \"kind\": \"CI\", \"url\": \"…\" }\n  ]\n}\n```\n\n**Actor/time attribution rule (repo-aligned):**\n`actor_id` MUST be derived by the daemon from peer credentials (as `ClaimWork` already does); clients MUST NOT be the authority for `actor_id`.\n`created_at_ns` SHOULD equal the ledger event timestamp used to anchor the entry (or be derived directly from the daemon's authoritative clock source).\n\n**Kind allowlist (mandatory):** `kind` MUST be one of:\n\n* `HANDOFF_NOTE`\n* `IMPLEMENTER_TERMINAL`\n* `DIAGNOSIS`\n* `REVIEW_FINDING`\n* `REVIEW_VERDICT`\n* `GATE_NOTE`\n* `LINKOUT`\n\n**Normalization rule:** the daemon MUST verify that `entry_json.kind` equals request `kind` and `entry_json.dedupe_key` equals request `dedupe_key`. If the client omits `entry_id`, `actor_id`, or `created_at_ns`, the daemon MUST fill them prior to canonicalization. If the client supplies them, the daemon MUST overwrite them with authoritative values (fail-closed if overwriting would change a non-empty client value)."
            },
            {
              "type": "section",
              "title": "4.4 WorkAuthorityBindings: `apm2.work_authority_bindings.v1` (immutable, append-only)",
              "children": [],
              "data": {
                "heading_level": 3
              },
              "body": "Stored in CAS; anchored by `evidence.published` with category `WORK_AUTHORITY_BINDINGS`.\n\n**Purpose:** eliminate WorkRegistry as an authority source by recording all authority-relevant pins required by RFC-0018 §6.3 for claim → spawn → privileged actions.\n\n```json\n{\n  \"schema\": \"apm2.work_authority_bindings.v1\",\n  \"work_id\": \"W-…\",\n  \"role\": \"IMPLEMENTER\",\n  \"lease_id\": \"L-…\",\n  \"actor_id\": \"actor:uid:…:gid:…\",\n  \"claimed_at_ns\": 0,\n  \"transition_count\": 1,\n  \"policy_resolution\": {\n    \"resolved_policy_hash\": \"…\",\n    \"policy_resolved_ref\": \"…\",\n    \"resolved_risk_tier\": 2,\n    \"role_spec_hash\": \"…\",\n    \"context_pack_recipe_hash\": \"…\",\n    \"context_pack_hash\": \"…\",\n    \"capability_manifest_hash\": \"…\",\n    \"expected_adapter_profile_hash\": \"…\"\n  },\n  \"boundary_pins\": {\n    \"permeability_receipt_hash\": null,\n    \"stop_condition_hash\": \"…\",\n    \"typed_budget_contract_hash\": \"…\",\n    \"typed_budget_hash\": \"…\",\n    \"typed_budgets\": { \"entropy_budget\": 1234 },\n    \"stop_conditions\": [ { \"type\": \"manual_stop\" } ]\n  }\n}\n```\n\n---"
            }
          ],
          "data": {
            "heading_level": 2
          },
          "body": "All CAS documents in this RFC are **canonicalized JSON** using `apm2_core::determinism::canonicalize_json` and then hashed via the existing BLAKE3 content hash (same pattern used throughout `DurableCas`)."
        },
        {
          "type": "section",
          "title": "5. Ledger event model",
          "children": [
            {
              "type": "section",
              "title": "5.1 Canonical work lifecycle events (existing)",
              "children": [],
              "data": {
                "heading_level": 3
              },
              "body": "Use the existing protobuf `WorkEvent` types (`WorkOpened`, `WorkTransitioned`, `WorkCompleted`, `WorkAborted`, `WorkPrAssociated`) and their reducer (`crates/apm2-core/src/work/reducer.rs`).\n\nCanonical event types are dot-prefixed (as already referenced in `work/authority.rs`):\n\n* `work.opened`\n* `work.transitioned`\n* `work.completed`\n* `work.aborted`\n* `work.pr_associated`\n\n**Session boundary pins (required by RFC-0018 §6.3):** session-start events MUST record the complete boundary pin set used to spawn the episode. Implementation choice: extend `SessionStarted` in `proto/kernel_events.proto` to include these hash fields so `session.started` is replay-self-contained."
            },
            {
              "type": "section",
              "title": "5.2 Work graph events (new): `WorkGraphEvent`",
              "children": [],
              "data": {
                "heading_level": 3
              },
              "body": "We introduce a new protobuf message family in `proto/kernel_events.proto`:\n\n```proto\n// Kernel events for the mutable dependency graph.\n// NOTE: event types are `work_graph.*` (do not start with `work.`) to avoid WorkReducer decoding.\n\nmessage WorkGraphEvent {\n  oneof event {\n    WorkEdgeAdded edge_added = 1;\n    WorkEdgeRemoved edge_removed = 2;\n    WorkEdgeWaived edge_waived = 3;\n  }\n}\n\nenum WorkEdgeType {\n  WORK_EDGE_TYPE_UNSPECIFIED = 0;\n  WORK_EDGE_TYPE_BLOCKS = 1;\n}\n\nmessage WorkEdgeAdded {\n  string edge_id = 1;          // \"EDGE-…\" unless caller supplies\n  string from_work_id = 2;\n  string to_work_id = 3;\n  WorkEdgeType edge_type = 4;\n  string rationale = 5;\n  string dedupe_key = 6;       // required when edge_id not supplied (idempotency)\n}\n\nmessage WorkEdgeRemoved {\n  string edge_id = 1;\n  string from_work_id = 2;\n  string to_work_id = 3;\n  WorkEdgeType edge_type = 4;\n  string rationale = 5;\n}\n\nmessage WorkEdgeWaived {\n  string edge_id = 1;\n  string from_work_id = 2;\n  string to_work_id = 3;\n  WorkEdgeType edge_type = 4;\n  string waiver_id = 5;\n  uint64 expires_at_ns = 6;\n  string rationale = 7;\n}\n```\n\nCanonical event types:\n\n* `work_graph.edge.added`\n* `work_graph.edge.removed`\n* `work_graph.edge.waived`\n\n**Why separate from WorkEvent:** WorkReducer currently rejects unknown `WorkEvent` variants; work graph should not require touching the work state machine reducer."
            },
            {
              "type": "section",
              "title": "5.3 Work context anchoring via evidence events (existing event, extended categories)",
              "children": [],
              "data": {
                "heading_level": 3
              },
              "body": "We use the existing protobuf `EvidenceEvent::Published` and extend evidence categories.\n\nCanonical event type:\n\n* `evidence.published`\n\nCategory additions in `crates/apm2-core/src/evidence/category.rs`:\n\n* `WORK_CONTEXT_ENTRY`\n* `WORK_AUTHORITY_BINDINGS`\n* `WORK_LOOP_PROFILE`\n\nThis avoids inventing a parallel “context event family” and leverages the evidence pipeline already present."
            },
            {
              "type": "section",
              "title": "5.4 PR association and repo identity (make collisions impossible without bloating work state)",
              "children": [],
              "data": {
                "heading_level": 3
              },
              "body": "Repo identity already lives in the WorkSpec proposed by this RFC (`WorkSpec.repo.owner/name`) and is\nimmutable by construction. The reducer-facing `Work` state only needs `(pr_number, commit_sha)` to\nsupport CI/gate association; projections that need `(repo_owner, repo_name)` can join against WorkSpec\nvia `spec_snapshot_hash`.\n\nThis avoids a high-churn proto change to `WorkPrAssociated` and avoids duplicating repo identity across\nmultiple event streams.\n\nDesign rule:\n\n* `work.pr_associated` (WorkEvent) remains `(work_id, pr_number, commit_sha)` only.\n* Repo identity for indexing and linkouts is sourced from WorkSpec; PR URL is recorded as a\n  `WORK_CONTEXT_ENTRY` linkout (preferred) rather than a WorkEvent field.\n\nProjection rule:\n\n* PR mapping must be keyed by `(repo_owner, repo_name, pr_number)` using repo identity from WorkSpec.\n\n---"
            }
          ],
          "data": {
            "heading_level": 2
          }
        },
        {
          "type": "section",
          "title": "6. Protocol changes (operator socket)",
          "children": [
            {
              "type": "section",
              "title": "6.0 Protocol conventions (applies to all new RPCs)",
              "children": [],
              "data": {
                "heading_level": 3
              },
              "body": "To prevent replay/duplication drift (and to align with RFC-0019's idempotent actuation requirement), all state-mutating RPCs introduced by this RFC MUST define:\n\n1. **Idempotency**: a deterministic dedupe key (explicit field or projection-enforced uniqueness) such that retrying the same request does not emit additional ledger events.\n2. **Actor attribution**: `actor_id` is derived by daemon from credentials; request fields may carry display hints but are not authoritative.\n3. **Atomicity boundary**:\n   * for \"CAS then ledger\" operations, the daemon stores the canonical bytes to CAS first (idempotent by hash), then appends the ledger event.\n   * if ledger append fails, the CAS object is allowed to exist \"unreferenced\" (garbage-collectable later); the daemon MUST NOT emit a partial ledger event that references a CAS hash that was not successfully stored.\n4. **Sequence correctness for work transitions**:\n   * any emission of `work.transitioned` MUST supply correct `previous_transition_count` as required by `apm2_core::work::WorkReducer` (monotone, fail-closed)."
            },
            {
              "type": "section",
              "title": "6.0.1 RPC contract: atomicity, idempotency, and error mapping (required)",
              "children": [
                {
                  "type": "section",
                  "title": "6.0.1.1 Atomicity rule (daemon)",
                  "children": [],
                  "data": {
                    "heading_level": 4
                  },
                  "body": "For any RPC that writes both CAS and ledger:\n\n1. Canonicalize + validate input (fail fast).\n2. Store artifact to CAS first (content addressed; duplicates are no-ops).\n3. Append the anchoring ledger event second.\n\nIf step (3) fails, the CAS object may be orphaned, but the truth plane remains consistent.\nThe daemon MAY implement a best-effort orphan reaper, but correctness must not depend on it."
                },
                {
                  "type": "section",
                  "title": "6.0.1.2 Idempotency rules (per RPC)",
                  "children": [],
                  "data": {
                    "heading_level": 4
                  },
                  "body": "* `OpenWork`: idempotent on `work_id`.\n  * If `work_id` exists with the same `spec_snapshot_hash`, return success (no-op).\n  * If `work_id` exists with a different `spec_snapshot_hash`, return `ALREADY_EXISTS`.\n* `ClaimWorkV2`: idempotent on `(work_id, role, actor_id)`.\n  * Same actor re-claim returns existing lease.\n  * Different actor returns `FAILED_PRECONDITION` (\"already claimed\").\n* `PublishWorkLoopProfile`: idempotent on `(work_id, dedupe_key)`.\n* `PublishWorkContextEntry`: idempotent on `(work_id, kind, dedupe_key)` (as already stated).\n* `RecordWorkPrAssociation`: idempotent on `(work_id, pr_number, commit_sha)` and SHOULD be checked\n  against existing association to avoid \"PR flapping.\"\n* Work graph RPCs:\n  * `AddWorkEdge` is idempotent on `(from_work_id, to_work_id, edge_type, dedupe_key)`; daemon derives `edge_id` deterministically if not supplied.\n  * `RemoveWorkEdge` and `WaiveWorkEdge` are idempotent by `edge_id`."
                },
                {
                  "type": "section",
                  "title": "6.0.1.3 Error mapping",
                  "children": [],
                  "data": {
                    "heading_level": 4
                  },
                  "body": "Map to existing `PrivilegedErrorCode` variants in `proto/apm2d_runtime_v1.proto`:\n\n* invalid schema / canonicalization failure / invalid hashes → `INVALID_ARGUMENT`\n* missing work → `WORK_NOT_FOUND`\n* missing session → `SESSION_NOT_FOUND`\n* missing edge / missing artifact reference → `VALIDATION_FAILED`\n* violates dependency closure / cycle detected / graph policy violation → `CAPABILITY_REQUEST_REJECTED`\n* lease/role mismatch / role not authorized for operation → `CAPABILITY_DENIED` (or `PERMISSION_DENIED` when the caller lacks daemon-level privilege)\n* idempotency conflict (same key, different content) → `VALIDATION_FAILED` (include a stable machine-readable reason string)"
                }
              ],
              "data": {
                "heading_level": 3
              },
              "body": "Many of the new RPCs have the shape \"store bytes in CAS, then append an anchoring ledger event.\"\nWithout explicit atomicity/idempotency rules, retries will produce divergent state and projections."
            },
            {
              "type": "section",
              "title": "6.1 OpenWork (new)",
              "children": [],
              "data": {
                "heading_level": 3
              },
              "body": "**Purpose:** create a work item with a stable `work_id` and an immutable WorkSpec hash, without implicitly claiming it.\n\nRequest:\n\n```proto\nmessage OpenWorkRequest {\n  string work_id = 1;\n  bytes work_spec_json = 2; // canonical JSON bytes\n  repeated string requirement_ids = 3;\n  repeated string parent_work_ids = 4; // optional legacy field; edges are preferred\n}\n```\n\nBehavior:\n\n1. Canonicalize JSON (`canonicalize_json`)\n2. Store to CAS; get `spec_hash`\n3. Append canonical ledger event `work.opened` (payload = `WorkEvent{opened=…}`)\n4. Emit pulses for `work.<work_id>.events`"
            },
            {
              "type": "section",
              "title": "6.2 ClaimWork v2 (new semantics; keep v1 temporarily)",
              "children": [],
              "data": {
                "heading_level": 3
              },
              "body": "Current `ClaimWork` generates a new `work_id` and writes to WorkRegistry. We add a new RPC that claims an existing work.\n\nRequest:\n\n```proto\nmessage ClaimWorkV2Request {\n  string work_id = 1;\n  WorkRole role = 2; // IMPLEMENTER, REVIEWER, etc.\n  bytes work_loop_profile_hash = 3; // optional override; else daemon default\n}\n```\n\nDaemon behavior:\n\n* Validate work exists (`work.opened` present)\n* Enforce dependency closure for implementer claims (see §7)\n* Transition:\n\n  * IMPLEMENTER: `work.transitioned(Open -> Claimed)`\n  * REVIEWER: `work.transitioned(ReadyForReview -> Review)`\n* Issue/renew lease + store authority bindings (see §8; this removes WorkRegistry as authority)\n* Return lease/session capability material consistent with current claim response patterns\n\n**Bridge rule:** Keep existing `ClaimWork` for “queue claim” until downstream is migrated, but treat it as legacy and ensure it opens work explicitly (calls OpenWork internally) rather than implicitly synthesizing `work.opened`."
            },
            {
              "type": "section",
              "title": "6.3 Add/Remove/Waive WorkEdge (new)",
              "children": [],
              "data": {
                "heading_level": 3
              },
              "body": "Requests (authorization + idempotency are explicit):\n\n* `AddWorkEdgeRequest { from_work_id, to_work_id, edge_type, rationale, dedupe_key, lease_id }`\n  * `lease_id` MUST be a valid `COORDINATOR` lease for `to_work_id` (see §7.6).\n* `RemoveWorkEdgeRequest { edge_id, from_work_id, to_work_id, edge_type, rationale, lease_id }`\n* `WaiveWorkEdgeRequest { edge_id, from_work_id, to_work_id, edge_type, expires_at_ns, rationale, lease_id }`\n\nEmit `work_graph.*` events and update projections."
            },
            {
              "type": "section",
              "title": "6.4 PublishWorkContextEntry (new)",
              "children": [],
              "data": {
                "heading_level": 3
              },
              "body": "Request:\n\n```proto\nmessage PublishWorkContextEntryRequest {\n  string work_id = 1;\n  string kind = 2;\n  string dedupe_key = 3;\n  bytes entry_json = 4; // canonical JSON bytes\n}\n```\n\nDaemon behavior:\n\n1. Validate + canonicalize `entry_json` (schema id + bounded decode).\n2. Fill/overwrite daemon-authoritative fields (`entry_id`, `actor_id`, `created_at_ns`) and re-canonicalize.\n   * `entry_id` MUST be derived deterministically from `(work_id, kind, dedupe_key)` per §4.0.1.\n3. Store canonical bytes to CAS → `entry_hash`\n4. Append `evidence.published` (protobuf `EvidencePublished`) with:\n   * `category = WORK_CONTEXT_ENTRY`\n   * `artifact_hash = entry_hash`\n   * `artifact_size = len(canonical_entry_bytes)`\n   * `classification = \"INTERNAL\"` (unless explicitly overridden by a policy-controlled surface)\n   * `verification_command_ids = []` (work context entries are not verification results)\n   * `metadata` includes `kind=<kind>` and `dedupe_key=<dedupe_key>` (for low-cost indexing)\n5. Enforce idempotency on `(work_id, kind, dedupe_key)` via projection uniqueness; on duplicate, return success without emitting additional events.\n\n**Note:** `EvidenceReducer` rejects duplicate `evidence_id`. This RFC requires `evidence_id = entry_id` (see §4.0.1)."
            },
            {
              "type": "section",
              "title": "6.5 RecordWorkPrAssociation (new)",
              "children": [],
              "data": {
                "heading_level": 3
              },
              "body": "Because the daemon does not speak GitHub, the CLI must supply PR info.\n\nRequest:\n\n```proto\nmessage RecordWorkPrAssociationRequest {\n  string work_id = 1;\n  uint64 pr_number = 2;\n  string commit_sha = 3; // 40-hex; daemon validates\n  string pr_url = 4;     // optional; stored as a linkout context entry when present\n}\n```\n\nEmit `work.pr_associated` canonical work event and (optionally) also publish a `WORK_CONTEXT_ENTRY` LINKOUT."
            },
            {
              "type": "section",
              "title": "6.6 DispatchImplementer/DispatchReviewer (recommended convenience)",
              "children": [],
              "data": {
                "heading_level": 3
              },
              "body": "This makes the daemon authoritative over workspace allocation and reduces CLI/agent drift.\n\n* `DispatchImplementerRequest { work_id, work_loop_profile_hash? }`\n\n  * Allocates workspace path deterministically (see §9), ensures directory exists, then calls internal SpawnEpisode with correct parameters, then emits `session.started` (canonical).\n* Similar for reviewer."
            },
            {
              "type": "section",
              "title": "6.7 PublishWorkLoopProfile (new; required to make WorkLoopProfile \"mutable\")",
              "children": [],
              "data": {
                "heading_level": 3
              },
              "body": "Request:\n\n```proto\nmessage PublishWorkLoopProfileRequest {\n  string work_id = 1;\n  string dedupe_key = 2;     // required for idempotency (e.g., \"default\", \"ops_override_2026_02_18\")\n  bytes profile_json = 3;    // canonical JSON bytes for apm2.work_loop_profile.v1\n}\n```\n\nDaemon behavior:\n\n1. Canonicalize + validate JSON schema (`apm2.work_loop_profile.v1`) via the fac schema registry.\n2. Reject empty `dedupe_key`.\n3. Store canonical bytes to CAS → `profile_hash`\n4. Append `evidence.published` with deterministic `evidence_id` derived from `(work_id, dedupe_key)` per §4.0.1, category `WORK_LOOP_PROFILE`, `evidence_hash=profile_hash`, and metadata containing `dedupe_key`.\n5. Projections treat the latest anchored profile as active for `(work_id)`.\n\n---"
            }
          ],
          "data": {
            "heading_level": 2
          },
          "body": "All additions are to `proto/apm2d_runtime_v1.proto` and implemented in `crates/apm2-daemon/src/protocol/dispatch.rs`, with corresponding CLI client updates."
        },
        {
          "type": "section",
          "title": "7. Work graph semantics and claimability enforcement",
          "children": [
            {
              "type": "section",
              "title": "7.1 Edge type",
              "children": [],
              "data": {
                "heading_level": 3
              },
              "body": "Initial required edge type:\n\n* `BLOCKS` (`WORK_EDGE_TYPE_BLOCKS`): prerequisite (`from_work_id`) must be `Completed` or waived before dependent (`to_work_id`) is implementer-claimable."
            },
            {
              "type": "section",
              "title": "7.2 Claimability rule (implementer role)",
              "children": [],
              "data": {
                "heading_level": 3
              },
              "body": "A work **cannot** be claimed for implementation if it has any unsatisfied incoming `BLOCKS` edges:\n\n* Unsatisfied = prerequisite not `Done/Completed` and no active waiver.\n\nWhere this is enforced:\n\n* In daemon handler for `ClaimWorkV2(IMPLEMENTER)` **and** in WorkDoctor recommendation logic."
            },
            {
              "type": "section",
              "title": "7.3 Waivers",
              "children": [],
              "data": {
                "heading_level": 3
              },
              "body": "Waivers are separate events, do not mutate history:\n\n* A waiver applies to an edge id\n* It may have expiry\n* It must be included in doctor diagnostics"
            },
            {
              "type": "section",
              "title": "7.4 Edge identifiers, idempotency, and cycles (required for implementability)",
              "children": [],
              "data": {
                "heading_level": 3
              },
              "body": "This RFC introduces mutable DAG edges; without explicit edge idempotency and cycle handling the system\nwill diverge under retries and/or deadlock under accidental cycles.\n\n* **Edge IDs**\n  * Caller MAY supply `edge_id`, otherwise daemon MUST derive:\n    * `edge_id = \"EDGE-\" + blake3(\"WORK_EDGE\" || from_work_id || to_work_id || edge_type || dedupe_key)`\n  * `dedupe_key` required when caller does not supply `edge_id`.\n\n* **Idempotency**\n  * `AddWorkEdge` idempotent on `(from_work_id, to_work_id, edge_type, dedupe_key)`.\n  * `RemoveWorkEdge` / `WaiveWorkEdge` idempotent by `edge_id`.\n\n* **Cycle detection**\n  * Reject edges creating cycles in the **active** BLOCKS graph (removed/waived edges excluded).\n  * Implementation MUST be bounded and fail-closed on bound exceed."
            },
            {
              "type": "section",
              "title": "7.5 Late edges and in-flight work (explicit policy)",
              "children": [],
              "data": {
                "heading_level": 3
              },
              "body": "If a `BLOCKS` edge is added where `to_work_id` is already `Claimed`/`InProgress`/`CiPending`:\n\n* The edge is still recorded (history is append-only).\n* The daemon MUST NOT auto-transition the work state (the `WorkReducer` state machine remains the only\n  authority for work state transitions).\n* Doctor output MUST surface the late edge as a high-severity diagnostic and recommend either:\n  * adding a waiver, or\n  * intentionally transitioning the work to `Blocked` via a policy-controlled system actor."
            },
            {
              "type": "section",
              "title": "7.6 Edge mutation authorization (mandatory)",
              "children": [],
              "data": {
                "heading_level": 3
              },
              "body": "Work graph edits change claimability and therefore admission behavior. They are **not** implementer-controlled.\n\n**Authorization rule:** edge mutations MUST require either:\n\n1. an active `COORDINATOR` lease for `to_work_id`, provided in the request, or\n2. a daemon-internal system actor.\n\n**Audit rule:** actor identity is taken from the ledger envelope; clients MUST NOT set `actor_id` in payloads.\n\n---"
            }
          ],
          "data": {
            "heading_level": 2
          }
        },
        {
          "type": "section",
          "title": "8. Eliminating WorkRegistry as authority (hard requirement)",
          "children": [
            {
              "type": "section",
              "title": "8.1 What WorkRegistry currently contains that ledger does not",
              "children": [],
              "data": {
                "heading_level": 3
              },
              "body": "WorkRegistry stores (at least):\n\n* Claim actor identity\n* Role\n* Lease id\n* Policy resolution hashes (role_spec_hash, context_pack_recipe_hash, expected_adapter_profile_hash, stop condition hash, etc.)\n* Potentially other binding material used in `handle_spawn_episode` validations\n\nThis is a direct violation of “ledger + CAS reconstructibility.”"
            },
            {
              "type": "section",
              "title": "8.2 Replacement: Authority Bindings as CAS + ledger anchor",
              "children": [
                {
                  "type": "section",
                  "title": "Ledger anchoring: use `evidence.published` (not `work.*`)",
                  "children": [],
                  "data": {
                    "heading_level": 4
                  },
                  "body": "Do **not** introduce `work.authority_bound` as written in the previous draft. Any `work.*` event type\nis decoded as a `WorkEvent` by `WorkReducer`; a standalone `WorkAuthorityBound` payload would hard-fail\nreduction.\n\nInstead, authority bindings are anchored using the existing evidence pipeline:\n\n* emit `evidence.published`\n* `category = WORK_AUTHORITY_BINDINGS`\n* `evidence_hash = bindings_hash` (CAS hash of `apm2.work_authority_bindings.v1`)\n* `metadata` MUST include: `role`, `lease_id`, and (optionally) `policy_resolution_hash` so that\n  projections can be built without fetching the CAS document in the hot path.\n\nSpawnEpisode then reads bindings from projections/CAS instead of WorkRegistry.\n\n**Outcome:** WorkRegistry becomes a derived cache at most, then removable.\n\n---"
                }
              ],
              "data": {
                "heading_level": 3
              },
              "body": "Introduce a CAS document:\n\n* `apm2.work_authority_bindings.v1`\n\nThis document must contain the *exact* authority-relevant material currently persisted in WorkRegistry\n(`WorkClaim`, `PolicyResolution`, custody domains, permeability receipt references, etc.) so that\n`handle_spawn_episode` can be implemented purely as \"read projections + fetch CAS artifacts.\"\n\nGrounding in repo reality:\n\n* `WorkClaim` and `PolicyResolution` already exist as concrete structs in\n  `crates/apm2-daemon/src/protocol/dispatch.rs`.\n* `TransitionAuthorityBindings` (including `capability_manifest_hash`, `context_pack_hash`,\n  `stop_condition_hash`, `typed_budget_contract_hash`, and optional `permeability_receipt_hash`) is\n  already derived and validated in `handle_spawn_episode` via `derive_transition_authority_bindings`\n  and `validate_and_store_transition_authority`."
            }
          ],
          "data": {
            "heading_level": 2
          }
        },
        {
          "type": "section",
          "title": "9. Workspace management (configurable, deterministic)",
          "children": [
            {
              "type": "section",
              "title": "9.1 WorktreeManager (new daemon component)",
              "children": [],
              "data": {
                "heading_level": 3
              },
              "body": "Config sources, in order:\n\n1. `daemon.workspaces.*` config defaults\n2. `WorkLoopProfile.workspace.*` override\n\nDeterministic path:\n\n* `<root>/<repo_slug>/<work_id>/`\n\n  * repo_slug = `${owner}_${repo}`\n\nStrategies:\n\n* `git_worktree` (default)\n* `git_clone_shared` (fallback)\n\nPolicies:\n\n* `reuse_per_work=true` keeps workspace stable across nudges\n* `cleanup_on_complete=true` reaps after `work.completed`\n\n---"
            }
          ],
          "data": {
            "heading_level": 2
          },
          "body": "The daemon currently requires `SpawnEpisodeRequest.workspace_root` to exist and be provided by the caller. This produces drift and violates “daemon-governed loop.”"
        },
        {
          "type": "section",
          "title": "10. Implementer lifecycle (closed loop, terminal contract preserved)",
          "children": [
            {
              "type": "section",
              "title": "10.1 State machine (matches existing `WorkState` in `crates/apm2-core/src/work/state.rs`)",
              "children": [],
              "data": {
                "heading_level": 3
              },
              "body": "* `Open` → `Claimed` (ClaimWorkV2 implementer)\n* `Claimed` → `InProgress` (DispatchImplementer / SpawnEpisode)\n* `InProgress` → `CiPending` (CI processor acknowledges latest changeset published by **terminal command `apm2 fac push`**)\n* `CiPending` → `ReadyForReview` or `Blocked` (gate orchestrator/system actor)\n* `Blocked` → `InProgress` (fix loop)\n* `ReadyForReview` → `Review` (review claim)\n* `Review` → `Completed` (merge admission) or back to `InProgress` (rework loop)\n\n**Repo alignment note:** `WorkState::can_transition_to` currently allows `Review -> InProgress` but does not allow `Review -> Blocked`. \"Blocked\" should remain CI/gate-centric; review failures are rework (`InProgress`) or escalation (`NeedsInput` / `NeedsAdjudication`) depending on policy."
            },
            {
              "type": "section",
              "title": "10.2 Terminal contract (hard)",
              "children": [],
              "data": {
                "heading_level": 3
              },
              "body": "A session attempt is not “complete” unless:\n\n* A `WORK_CONTEXT_ENTRY` of kind `IMPLEMENTER_TERMINAL` exists with `dedupe_key=session_id`, **and**\n* A `WORK_CONTEXT_ENTRY` of kind `HANDOFF_NOTE` exists for the same session (same dedupe key or session-bound linkage)"
            },
            {
              "type": "section",
              "title": "10.3 `apm2 fac push` changes (bridge, not replacement)",
              "children": [],
              "data": {
                "heading_level": 3
              },
              "body": "Add:\n\n* `--work-id <id>` (or `--ticket-alias` resolving to work_id)\n\nRequired post-push behavior:\n\n1. Publish change set to daemon (`PublishChangeSet`) **bound to work_id**\n2. Record PR association (`RecordWorkPrAssociation`)\n3. Publish context entries:\n\n   * `HANDOFF_NOTE` (required)\n   * `IMPLEMENTER_TERMINAL` (required; idempotent dedupe)\n   * optional LINKOUTs (PR/CI)\n\nThen daemon transitions:\n\n* **This RFC's rule:** `apm2 fac push` MUST NOT emit any `work.transitioned` events. It publishes the latest changeset + required context markers only.\n\nInstead:\n\n* **CI processor responsibility:** a daemon-side CI processor observes `changeset_published` for the work's latest digest and emits:\n\n  * `work.transitioned(InProgress -> CiPending)` as actor `\"system:ci-processor\"`\n  * `work.transitioned(CiPending -> ReadyForReview)` **or** `work.transitioned(CiPending -> Blocked)` as actor `\"system:ci-processor\"` (these transitions are CI-restricted today by `WorkReducer`)."
            },
            {
              "type": "section",
              "title": "10.4 Reaper/nudge loop (new daemon WorkLoopManager)",
              "children": [],
              "data": {
                "heading_level": 3
              },
              "body": "Trigger conditions:\n\n* `session.terminated` arrives for an implementer session\n* work state remains `InProgress`\n* missing terminal contract markers\n\nBehavior:\n\n* schedule a nudge attempt using the same workspace\n* nudge content includes: current doctor status, missing markers, exact command to run (`apm2 fac push --work-id ... --handoff-note ...`)\n\nBudgets and backoff come from WorkLoopProfile; no hard-coded “3 nudges.”\n\n---"
            }
          ],
          "data": {
            "heading_level": 2
          }
        },
        {
          "type": "section",
          "title": "11. Gate loop + merge completion alignment",
          "children": [
            {
              "type": "section",
              "title": "11.1 CI actor identity (don’t hard-code string)",
              "children": [],
              "data": {
                "heading_level": 3
              },
              "body": "Repo reality: `WorkReducer` currently hard-codes `\"system:ci-processor\"` for CI-authorized transitions.\nChanging this is non-trivial because `WorkReducer` runs in `apm2-core` (no daemon config).\n\nFor this RFC's scope:\n\n* Keep `\"system:ci-processor\"` as the CI actor id to satisfy current reducer checks.\n* Track \"configurable CI actor id\" as an identity RFC follow-up that must also specify how reducer\n  configuration is plumbed (constructor parameter, environment override, or wrapper reducer)."
            },
            {
              "type": "section",
              "title": "11.2 Latest changeset rule",
              "children": [],
              "data": {
                "heading_level": 3
              },
              "body": "Gate outcomes must apply only to the latest changeset for a work.\n\nProjection requirement:\n\n* `work_latest_changeset(work_id -> changeset_digest)` maintained from `changeset_published` / canonical changeset events.\n\nGateOrchestrator transitions `CiPending -> ReadyForReview/Blocked` only if receipt binds to latest digest."
            },
            {
              "type": "section",
              "title": "11.3 Merge completion event naming bug fix (required)",
              "children": [],
              "data": {
                "heading_level": 3
              },
              "body": "`crates/apm2-daemon/src/gate/merge_executor.rs` currently writes a `WorkCompleted`-shaped event where `gate_receipt_id` field actually carries a merge receipt id (`merge-receipt-<sha>`). This must be renamed and semantically aligned:\n\n* Introduce `merge_receipt_id` field (or carry merge receipt hash in evidence bundle)\n* Make merge executor append:\n\n  * `merge.receipt_recorded` (or equivalent canonical)\n  * `work.completed` with evidence bundle that references merge receipt + final gate/review receipts\n\n---"
            }
          ],
          "data": {
            "heading_level": 2
          }
        },
        {
          "type": "section",
          "title": "12. Pulse plane: making wait push-based and correct",
          "children": [
            {
              "type": "section",
              "title": "12.1 Fix the type mismatch",
              "children": [],
              "data": {
                "heading_level": 3
              },
              "body": "Current pulse publisher assumes `KernelEvent` envelope decoding; in repo reality, commit notifications\nalready provide `(event_type, namespace)` and payload bytes may be either:\n* legacy JSON facts,\n* reducer-domain protobuf wrapper events, or\n* typed discriminant payloads (depending on which plane emitted the event).\n\nPulsePublisher must operate on:\n\n* `(event_type, namespace, payload_bytes)` and decode only when required."
            },
            {
              "type": "section",
              "title": "12.2 Multi-topic derivation (required)",
              "children": [],
              "data": {
                "heading_level": 3
              },
              "body": "Topic derivation must return `Vec<String>`, not a single topic, because:\n\n* work graph edges touch two work ids (and work_graph payloads MUST carry both ids so the deriver can be stateless)\n* receipts can affect both work and PR indices"
            },
            {
              "type": "section",
              "title": "12.3 Topic namespace",
              "children": [],
              "data": {
                "heading_level": 3
              },
              "body": "Standard topics:\n\n* `work.<work_id>.events`\n* `ledger.head` (required by RFC-0018 topic taxonomy; enables \"follow the chain\" consumers)\n* `work.<work_id>.gates.events` (optional)\n* `work.<work_id>.reviews.events` (optional)\n* `session.<session_id>.events`\n\nRule: anything that can change doctor output for a work MUST emit `work.<work_id>.events`."
            },
            {
              "type": "section",
              "title": "12.4 Typed discriminants vs dotted event types (explicit requirement)",
              "children": [],
              "data": {
                "heading_level": 3
              },
              "body": "Topic derivation must work for both:\n\n* dotted reducer-domain event types (`work.opened`, `work.transitioned`, …), and\n* typed discriminants (`WorkOpened`, `WorkTransitioned`, …) used by current topic derivation tests\n  and RFC-0018 `02_design_decisions.yaml`.\n\nImplementation guidance:\n\n* Maintain a parity mapping layer for work lifecycle events (reuse `crates/apm2-core/src/work/parity.rs`\n  concepts) so both forms map to identical work topics."
            },
            {
              "type": "section",
              "title": "12.5 CLI wait integration",
              "children": [],
              "data": {
                "heading_level": 3
              },
              "body": "Add operator client support for:\n\n* `SubscribePulse`\n* `WaitForPulse`\n\nUpdate doctor flows (`apm2 fac doctor` and/or new `apm2 work doctor`) so `--wait` subscribes to:\n\n* `work.<work_id>.>` and re-runs doctor evaluation on pulse arrival.\n\n---"
            }
          ],
          "data": {
            "heading_level": 2
          }
        },
        {
          "type": "section",
          "title": "13. Projections (derived, replayable)",
          "children": [
            {
              "type": "section",
              "title": "13.1 work_edges",
              "children": [],
              "data": {
                "heading_level": 3
              },
              "body": "(as in the earlier draft; unchanged conceptually)"
            },
            {
              "type": "section",
              "title": "13.2 work_context",
              "children": [],
              "data": {
                "heading_level": 3
              },
              "body": "* keyed by `(work_id, entry_id)`\n* unique index on `(work_id, kind, dedupe_key)` where dedupe_key not null"
            },
            {
              "type": "section",
              "title": "13.3 work_authority_bindings",
              "children": [],
              "data": {
                "heading_level": 3
              },
              "body": "* keyed by `(work_id, role)`\n* stores `lease_id`, `bindings_hash`, `evidence_id`, `claimed_at_ns`, released fields\n* derived from `evidence.published` where `category = WORK_AUTHORITY_BINDINGS`"
            },
            {
              "type": "section",
              "title": "13.4 work_latest_changeset",
              "children": [],
              "data": {
                "heading_level": 3
              },
              "body": "* keyed by work_id\n* stores latest digest and time\n\n**Critical rule:** All these tables must be derivable from ledger + CAS. No WorkRegistry-only state.\n\n---"
            }
          ],
          "data": {
            "heading_level": 2
          },
          "body": "Add projection tables (daemon projection DB):"
        },
        {
          "type": "section",
          "title": "14. Migration plan (no cutover cliff, but no permanent dual truth)",
          "children": [
            {
              "type": "section",
              "title": "Phase 0 — Ledger unification (blocking prerequisite)",
              "children": [],
              "data": {
                "heading_level": 3
              },
              "body": "Implement a daemon startup migration that turns the core `events` table into the sole append target.\n\nGrounding in repo reality:\n\n* `determine_read_mode` selects `LedgerReadMode::LegacyLedgerEvents` when `ledger_events` exists and `events` is empty.\n\n  * Canonical append APIs then fail-closed via `LedgerStorageError::LegacyModeReadOnly`.\n  * If we copy into `events` without removing/renaming `ledger_events`, startup will fail fast with `LedgerReadModeError::AmbiguousSchemaState`.\n\n  Phase 0 must therefore both (a) migrate rows and (b) eliminate the legacy table name from the active schema.\n\n* The existing compat view `events_legacy_compat_v1` returns `NULL` for `prev_hash`/`event_hash`,\n  which prevents core-ledger appenders from building a hash chain (`last_event_hash()` falls back to\n  genesis when `event_hash` is NULL).\n\nMigration requirements (implementation-grade):\n\n1. **Single transaction, exclusive lock**\n   * Acquire an exclusive SQLite transaction for the duration of the copy + hash-chain computation.\n\n2. **Preserve ordering (legacy truth)**\n   * Read `ledger_events` ordered by `rowid ASC` (matches legacy hash-chain ordering; see `backfill_hash_chain`).\n   * Insert into `events` in the same order. `seq_id` is auto-assigned by `events`; ordering is what matters.\n\n3. **Populate required core columns**\n   * `record_version = 1`\n   * `namespace = 'default'` (schema default)\n   * `session_id`: parse for session events; else set `''` (empty string).\n   * Leave `schema_digest`, `canonicalizer_id`, `consensus_*`, `hlc_*` NULL during migration.\n\n4. **Compute a real 32-byte hash chain**\n   * `event_hash = blake3(prev_hash || payload_bytes)` with genesis `prev_hash = 32x00`, via `apm2_core::crypto::EventHasher`.\n\n5. **Signature handling (explicitly unverified)**\n   * Copy signature bytes unchanged; do not attempt verification during migration.\n\n6. **Eliminate ambiguous schema state**\n   * Rename `ledger_events` to `ledger_events_legacy_frozen` (or export+drop) so `determine_read_mode` cannot enter `AmbiguousSchemaState`.\n\n7. **Freeze legacy writers**\n   * Hard-fail any codepath that tries to write the legacy emitter; new facts MUST append to `events`.\n\n8. **Idempotency**\n   * If `events` already contains rows, migration is a no-op.\n   * If migration partially completed, fail fast (do not attempt to continue)."
            },
            {
              "type": "section",
              "title": "Phase 1 — Work open (CAS WorkSpec + work.opened)",
              "children": [],
              "data": {
                "heading_level": 3
              },
              "body": "* Add `OpenWork` RPC and `apm2 work open --from-ticket <yaml>` importer\n* Store WorkSpec in CAS and emit `work.opened`\n* Emit ticket alias bindings via WorkSpec metadata; wire into alias reconciliation gate (replacing current identity stub)"
            },
            {
              "type": "section",
              "title": "Phase 2 — `fac push --work-id` terminal contract bridge",
              "children": [],
              "data": {
                "heading_level": 3
              },
              "body": "* Extend `apm2 fac push` to accept `--work-id`\n* After GitHub push/PR update, call daemon:\n\n  * PublishChangeSet(work_id)\n  * RecordWorkPrAssociation(work_id, repo, pr_number, sha)\n  * PublishWorkContextEntry(HANDOFF_NOTE, IMPLEMENTER_TERMINAL)\n  * Transition InProgress → CiPending"
            },
            {
              "type": "section",
              "title": "Phase 3 — Work graph + dependency enforcement",
              "children": [],
              "data": {
                "heading_level": 3
              },
              "body": "* Add work graph RPCs and projections\n* Enforce in claim + doctor"
            },
            {
              "type": "section",
              "title": "Phase 4 — Reviewer bridge + configurable nudge",
              "children": [],
              "data": {
                "heading_level": 3
              },
              "body": "* On verdict set, publish WorkContext entries and canonical review receipt events\n* Remove hard-coded nudge caps from `fac_review` path by moving to WorkLoopProfile"
            },
            {
              "type": "section",
              "title": "Phase 5 — Merge completion alignment + naming fix",
              "children": [],
              "data": {
                "heading_level": 3
              },
              "body": "* Emit merge receipt + work.completed atomically and consistently"
            },
            {
              "type": "section",
              "title": "Phase 6 — Remove WorkRegistry authority",
              "children": [],
              "data": {
                "heading_level": 3
              },
              "body": "* All authority reads come from projections over ledger + CAS\n* WorkRegistry becomes an internal cache or is deleted\n\n---"
            }
          ],
          "data": {
            "heading_level": 2
          }
        },
        {
          "type": "section",
          "title": "15. Acceptance tests (system-level)",
          "children": [],
          "data": {
            "heading_level": 2
          },
          "body": "AT-0: Ledger unification\n\n* Start with db containing legacy `ledger_events` only (events empty)\n* Run migration\n* Verify core ledger read mode becomes canonical and daemon can append new events\n\nAT-1: Work open + graph enforcement\n\n1. Open A, Open B\n2. Add edge A BLOCKS B\n3. Claim B (implementer) must fail with “blocked by A”\n4. Complete A, then claim B succeeds\n\nAT-2: Implementer terminal contract\n\n1. Claim + dispatch implementer on W\n2. End session without push → doctor recommends terminal command + nudge scheduled\n3. Run `apm2 fac push --work-id W --handoff-note …`\n4. Verify context entries exist (dedupe), state transitions to CiPending\n\nAT-3: PR association repo identity\n\n* RecordWorkPrAssociation with repo owner/name\n* Projection keys `(owner,name,pr_number)` map to work_id without collisions\n\nAT-4: Pulse-driven wait\n\n* Subscribe to `work.<id>.>`\n* Append a relevant event (context publish or transition)\n* Verify pulse delivered and doctor reevaluated without polling\n\nAT-5: Merge completion alignment\n\n* Merge executor emits merge receipt + work.completed\n* Evidence bundle references correct receipt ids; no misnamed `gate_receipt_id`\n\n---"
        },
        {
          "type": "section",
          "title": "16. Key design corrections vs the initial proposal",
          "children": [],
          "data": {
            "heading_level": 2
          },
          "body": "1. **Ticket IDs are aliases, not canonical work ids**: the repo already contains alias reconciliation infrastructure; use it instead of forcing `work_id == TCK-*`.\n2. **Core ledger can be read-only today**: any kernel-native plan must include a ledger unification migration or a clean new ledger file strategy.\n3. **No canonical `work.claimed` event in the target reducer space**: claim is a `work.transitioned(Open→Claimed)`; additional authority bindings must be anchored separately (this RFC uses `evidence.published` with category `WORK_AUTHORITY_BINDINGS`).\n4. **Pulse plane must derive topics from actual canonical event types**: current `KernelEvent`-envelope decoding assumptions are inconsistent with reducer-facing event families; fix is required for push-based waits to be real.\n\n---"
        },
        {
          "type": "section",
          "title": "17. Implementation map (first cut)",
          "children": [
            {
              "type": "section",
              "title": "Daemon",
              "children": [],
              "data": {
                "heading_level": 3
              },
              "body": "* Add unification migration: `crates/apm2-core/src/ledger/storage.rs` + daemon startup path\n* New RPC handlers: `crates/apm2-daemon/src/protocol/dispatch.rs`\n\n  * OpenWork, ClaimWorkV2, AddWorkEdge/Remove/Waive, PublishWorkContextEntry, RecordWorkPrAssociation\n* New work loop manager: `crates/apm2-daemon/src/work/*` (new module)\n* Projections: extend `crates/apm2-daemon/src/projection/worker.rs` (or new projection module)\n* EvidenceCategory: extend `crates/apm2-core/src/evidence/category.rs`\n* Proto changes: `proto/kernel_events.proto`, `proto/apm2d_runtime_v1.proto`"
            },
            {
              "type": "section",
              "title": "CLI",
              "children": [],
              "data": {
                "heading_level": 3
              },
              "body": "* `apm2 fac push`: `crates/apm2-cli/src/commands/fac.rs` + `fac_review/push.rs`\n* Add protocol client calls for new RPCs\n* Add `apm2 work open`, `apm2 work doctor` (or extend `fac doctor` to accept work id)"
            },
            {
              "type": "section",
              "title": "Pulse",
              "children": [],
              "data": {
                "heading_level": 3
              },
              "body": "* Fix `PulsePublisher` decode path and topic deriver:\n\n  * `crates/apm2-daemon/src/protocol/pulse_outbox.rs`\n  * `crates/apm2-daemon/src/protocol/topic_derivation.rs`\n\n---"
            }
          ],
          "data": {
            "heading_level": 2
          }
        },
        {
          "type": "section",
          "title": "18. Resolved decisions and follow-ups",
          "children": [
            {
              "type": "section",
              "title": "18.1 Actor identity and signature mode",
              "children": [],
              "data": {
                "heading_level": 3
              },
              "body": "* Actor IDs remain daemon-derived strings (not verifying keys).\n* Ledger writes run in unverified mode for vNext; signatures retained for tamper evidence.\n* Verified actor identity is deferred to a dedicated identity RFC."
            },
            {
              "type": "section",
              "title": "18.2 Canonical event naming and encoding convergence",
              "children": [],
              "data": {
                "heading_level": 3
              },
              "body": "* Work/evidence lifecycle: only `work.*`, `session.*`, `evidence.*` post-Phase-2; freeze legacy underscore lifecycle emissions.\n* Kernel facts with underscore names may keep event_type strings, but payload encoding converges to protobuf in core ledger; JSON supported only for historical migrated rows."
            },
            {
              "type": "section",
              "title": "18.3 Deterministic changeset bundle construction",
              "children": [],
              "data": {
                "heading_level": 3
              },
              "body": "* `apm2 fac push` MUST build changesets via `crates/apm2-core/src/fac/changeset_bundle.rs` and publish the computed digest + CAS hash."
            },
            {
              "type": "section",
              "title": "18.4 Reducer configuration plumbing",
              "children": [],
              "data": {
                "heading_level": 3
              },
              "body": "* Keep `CI_SYSTEM_ACTOR_ID = \"system:ci-processor\"`; configurable reducer identities are out of scope."
            },
            {
              "type": "section",
              "title": "18.5 Size bounds and schema validation",
              "children": [],
              "data": {
                "heading_level": 3
              },
              "body": "* Hard caps in §4.0 are mandatory and fail-closed."
            },
            {
              "type": "section",
              "title": "18.6 Backfilling legacy WorkRegistry authority",
              "children": [],
              "data": {
                "heading_level": 3
              },
              "body": "* During Phase 6, backfill `WORK_AUTHORITY_BINDINGS` evidence for each active `work_claims` row.\n* Missing boundary pins MUST be marked incomplete; incomplete claims are non-authoritative for new episode spawns until re-claimed under ClaimWorkV2."
            }
          ],
          "data": {
            "heading_level": 2
          },
          "body": "This RFC removes \"open issue\" blockers by making explicit vNext decisions."
        }
      ],
      "data": {
        "summary": "**Unifying Work Object, Work Graph, Work Context, and Implementer/Reviewer Loops onto the Core Ledger + CAS (while preserving `apm2 fac push` as the terminal command through cutover)**",
        "target_outcomes": [
          "G1. Single canonical truth plane for FAC: Core ledger `events` table + CAS.",
          "G2. No SQLite-only authority: all authority decisions needed for “what happens next” must be reconstructible from (ledger events + CAS artifacts) with deterministic projection logic.",
          "G3. Work graph as first-class: add/remove dependency edges post-open; enforce closure for claimability; support waivers without mutating history.",
          "G4. Work context stream as first-class: append-only, ledger-anchored, CAS-backed, queryable, replayable; supports handoffs, findings, diagnoses, linkouts.",
          "G5. Closed implementer + reviewer loops with daemon-governed nudging/reaping; terminal act preserved (`apm2 fac push`).",
          "G6. Pulse-driven waits: remove polling as the default “wait” mechanism; `--wait` subscribes to work-centric topics.",
          "G7. Configurable operational knobs: workspace roots, retry/nudge/backoff budgets are policy/config driven, not hard-coded in control-plane logic."
        ],
        "non_goals": [
          "NG1. Fully replacing GitHub or `fac_review` internals immediately.",
          "NG2. Requiring mediated tool execution (AdmissionKernel tool bridge) on the critical path. System must work in unmediated mode.",
          "NG3. Designing the final cryptographic actor identity model (hex key ids vs string identities) beyond what is required to make the FAC truth plane reconstructible and operational."
        ]
      },
      "body": "# RFC: Kernel-Native Forge Admission Cycle vNext\n\n**Unifying Work Object, Work Graph, Work Context, and Implementer/Reviewer Loops onto the Core Ledger + CAS (while preserving `apm2 fac push` as the terminal command through cutover)**\n\n**Repo scope:** `crates/apm2-core`, `crates/apm2-daemon`, `crates/apm2-cli`, `proto/*`, `documents/rfcs/*`\n**Primary documents referenced (in-repo):**\n\n* `documents/rfcs/RFC-0018/TECHNICAL_PROPOSAL_WORKOBJECT_LEDGER_CUTOVER.md`\n* `documents/rfcs/RFC-0019/AUTONOMOUS_FORGE_ADMISSION_CYCLE.md`\n  **Key code touchpoints referenced (in-repo):**\n* Legacy daemon ledger + registry: `crates/apm2-daemon/src/ledger.rs` (e.g. `work_claims`, `ledger_events`)\n* Core ledger read-mode split + legacy compat: `crates/apm2-core/src/ledger/storage.rs` (`determine_read_mode`, `append_verified`)\n* Work truth via projections (already moving directionally): `crates/apm2-daemon/src/work/authority.rs`, `crates/apm2-daemon/src/work/projection.rs`\n* Operator protocol handlers: `crates/apm2-daemon/src/protocol/dispatch.rs` (notably `handle_claim_work`, `handle_publish_changeset`, `handle_spawn_episode`)\n* CAS: `crates/apm2-daemon/src/cas/mod.rs`, `crates/apm2-core/src/evidence/cas.rs`\n* Pulse plane scaffolding: `crates/apm2-daemon/src/protocol/pulse_outbox.rs`, `topic_derivation.rs`, `pulse_topic.rs`\n* CLI entrypoints: `crates/apm2-cli/src/commands/fac.rs`, `crates/apm2-cli/src/commands/fac_review/push.rs`, `crates/apm2-cli/src/commands/work.rs`\n* Evidence categories: `crates/apm2-core/src/evidence/category.rs`\n\n---"
    }
  }
}