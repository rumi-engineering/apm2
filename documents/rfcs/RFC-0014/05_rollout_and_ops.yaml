rfc_rollout_and_ops:
  schema_version: "2026-01-28"

  rollout_strategy:
    overview: |
      The distributed consensus layer is deployed in four phases, each building on the
      previous while maintaining backward compatibility. Single-node operation remains
      the default until explicit cluster configuration is provided.

    phases:
      - id: PHASE-0
        name: "Foundation"
        description: |
          Prepare the codebase without changing runtime behavior. Introduce abstractions
          and schema extensions that are backward-compatible with existing single-node
          operation.
        deliverables:
          - "LedgerBackend trait extracted from existing Ledger"
          - "SqliteLedgerBackend wrapper (zero behavioral change)"
          - "EventMetadata struct with default values"
          - "Schema extension (nullable consensus columns)"
          - "Feature flag: distributed-consensus (disabled by default)"
        validation:
          - "All existing tests pass without modification"
          - "Single-node operation unchanged (verify via integration tests)"
          - "Schema migration runs successfully on existing databases"
        rollback: "Remove feature flag; revert to previous code"

      - id: PHASE-1
        name: "Replication"
        description: |
          Establish multi-node communication and leader-based replication without
          full consensus voting. Introduce Relay Holons for NAT traversal.
        deliverables:
          - "Peer discovery protocol (bootstrap nodes + gossip)"
          - "Relay Holon protocol (reverse-TLS management tunnels)"
          - "Mutual TLS for inter-node communication"
          - "Leader-based event replication"
          - "Genesis block agreement (adopting ledger head)"
          - "Basic anti-entropy sync (no CRDT merge yet)"
        validation:
          - "Nodes behind NAT establish connections via Relay Holon"
          - "Events replicate from leader to followers"
          - "Genesis block hash matches pre-existing ledger head"
          - "Follower can sync from leader after restart"
          - "Admission-critical authority operations remain disabled until PHASE-2"
        rollback: "Disable replication; fall back to single-node"

      - id: PHASE-2
        name: "Consensus"
        description: |
          Full BFT consensus for control plane events using HotStuff/PBFT. Quorum
          certificates required for authority operations.
        deliverables:
          - "HotStuff/PBFT BFT consensus implementation"
          - "Quorum certificate generation and verification"
          - "Leader election and view changes"
          - "StrictlyOrderedEvidence enforcement for Admission"
          - "HLC-based CRDT merge operators (LWW, GCounter, SetUnion)"
          - "Conflict recording via DefectRecorded events"
          - "Byzantine fault detection (equivocation)"
        validation:
          - "Control plane events finalized with 2f+1 signatures"
          - "Leader crash triggers successful election"
          - "Network partition maintains safety (no conflicting finality)"
          - "Data plane events converge via anti-entropy"
          - "Equivocation detected and recorded"
        rollback: "Downgrade to leader-based replication (PHASE-1)"

      - id: PHASE-3
        name: "Production"
        description: |
          Production hardening with HSM integration, comprehensive monitoring,
          and operational tooling.
        deliverables:
          - "HSM integration for T1 validator keys"
          - "Prometheus metrics for consensus health"
          - "Grafana dashboards for cluster monitoring"
          - "apm2-cli commands for cluster management"
          - "Automated key rotation schedule"
          - "Disaster recovery procedures"
        validation:
          - "Validator keys stored in HSM"
          - "Metrics exported and visible in dashboards"
          - "Key rotation completes without service interruption"
          - "DR procedures tested via chaos engineering"
        rollback: "Documented manual intervention procedures"

  migration_path:
    from_single_node:
      overview: |
        Migrating an existing single-node APM2 deployment to distributed mode
        preserves all historical events and hash chain integrity.

      steps:
        - step: 1
          action: "Backup existing database"
          command: "cp $APM2_DATA_DIR/ledger.db $APM2_DATA_DIR/ledger.db.backup"
          validation: "Backup file exists and is not corrupted"

        - step: 2
          action: "Run schema migration"
          command: "apm2-cli ledger migrate --to-version 0.2.0"
          validation: "Schema version updated; new columns added"

        - step: 3
          action: "Generate consensus genesis adopting existing head"
          command: "apm2-cli consensus genesis adopt --ledger $APM2_DATA_DIR/ledger.db"
          validation: "Genesis block created with genesis_hash matching existing ledger head hash"

        - step: 4
          action: "Sign genesis with root key"
          command: "apm2-cli consensus genesis sign --key-file /secure/t0-key.pem"
          validation: "Genesis block has valid root_signature"

        - step: 5
          action: "Configure validator set"
          command: "apm2-cli consensus config add-validator --id node1 --address node1:9090"
          validation: "Validator registered in genesis block"

        - step: 6
          action: "Start nodes with consensus enabled"
          command: "apm2d --consensus --genesis-file /path/to/genesis.json"
          validation: "Nodes connect and sync; consensus healthy"

      rollback_procedure:
        trigger: "Any validation failure or consensus instability"
        steps:
          - "Stop all nodes"
          - "Restore from backup: cp ledger.db.backup ledger.db"
          - "Start in single-node mode: apm2d (no --consensus flag)"
          - "Verify chain integrity: apm2-cli ledger verify-chain"

  operational_requirements:
    node_requirements:
      minimum_nodes: 4
      recommended_nodes: 7
      rationale: "3f+1 nodes for f=1 (4 nodes) or f=2 (7 nodes) Byzantine tolerance at local scale"

    scale_boundary:
      target_quorum_size: "4-7 nodes"
      latency_budget: "p99 < 500ms"
      scope: "Single namespace or holon; no global flat log"

    network_requirements:
      ports:
        - port: 9090
          protocol: TCP
          purpose: "Consensus protocol (inter-node)"
        - port: 9091
          protocol: TCP
          purpose: "Anti-entropy sync"
        - port: 9092
          protocol: TCP
          purpose: "Relay Holon tunnel (inbound on relay nodes)"
      nat_traversal:
        mechanism: "Reverse-TLS Management Tunnels via Relay Holons"
        constraint: "Worker nodes maintain outbound-only connection to Relay"
      firewall_rules:
        - "Allow 9090-9091/tcp between validator nodes (if internal)"
        - "Allow 9092/tcp outbound from workers to Relay"
        - "Allow 9092/tcp inbound on Relay from authorized nodes"

    tls_configuration:
      certificate_authority: "Per-network CA for mutual TLS"
      node_certificates: "Issued by network CA; renewed annually"
      key_rotation: "Quarterly rotation recommended"

  observability:
    metrics:
      - name: "apm2_consensus_proposals_total"
        type: counter
        labels: ["node_id", "outcome"]
        description: "Total consensus proposals made"

      - name: "apm2_consensus_finalization_latency_seconds"
        type: histogram
        labels: ["node_id"]
        description: "Time from proposal to finalization"

      - name: "apm2_consensus_leader_elections_total"
        type: counter
        labels: ["node_id", "reason"]
        description: "Leader election events"

      - name: "apm2_consensus_quorum_size"
        type: gauge
        labels: ["node_id"]
        description: "Current quorum requirement"

      - name: "apm2_consensus_validators_active"
        type: gauge
        labels: ["node_id"]
        description: "Number of active validators"

      - name: "apm2_antientropy_sync_events_total"
        type: counter
        labels: ["node_id", "direction"]
        description: "Events exchanged during anti-entropy sync"

      - name: "apm2_antientropy_conflicts_total"
        type: counter
        labels: ["node_id", "event_type", "resolution"]
        description: "Merge conflicts detected"

      - name: "apm2_schema_registry_entries"
        type: gauge
        labels: ["node_id"]
        description: "Number of registered schemas"

      - name: "apm2_byzantine_evidence_total"
        type: counter
        labels: ["node_id", "fault_type"]
        description: "Byzantine fault evidence generated"

    alerts:
      - name: "ConsensusNoLeader"
        condition: "apm2_consensus_leader_elections_total increases > 5 in 1m"
        severity: warning
        description: "Frequent leader elections indicate instability"

      - name: "ConsensusQuorumLost"
        condition: "apm2_consensus_validators_active < apm2_consensus_quorum_size"
        severity: critical
        description: "Insufficient validators for quorum"

      - name: "HighFinalizationLatency"
        condition: "histogram_quantile(0.99, apm2_consensus_finalization_latency_seconds) > 0.5"
        severity: warning
        description: "Consensus finalization taking too long"

      - name: "ByzantineFaultDetected"
        condition: "increase(apm2_byzantine_evidence_total[5m]) > 0"
        severity: critical
        description: "Byzantine behavior detected"

      - name: "AntiEntropyDivergence"
        condition: "increase(apm2_antientropy_conflicts_total[1h]) > 100"
        severity: warning
        description: "High rate of anti-entropy conflicts"

    dashboards:
      - name: "APM2 Consensus Overview"
        panels:
          - "Finalization latency (p50, p99)"
          - "Proposals per second"
          - "Active validators"
          - "Leader elections over time"

      - name: "APM2 Node Health"
        panels:
          - "Per-node proposal success rate"
          - "Anti-entropy sync status"
          - "Byzantine evidence events"
          - "Schema registry status"

  cli_commands:
    cluster_management:
      - command: "apm2-cli consensus status"
        description: "Show cluster health and leader info"
        output: "JSON with validators, leader, epoch, latest seq_id"

      - command: "apm2-cli consensus add-validator --id ID --address ADDR --key-file KEY"
        description: "Propose adding a new validator (requires governance vote)"

      - command: "apm2-cli consensus remove-validator --id ID"
        description: "Propose removing a validator (requires governance vote)"

      - command: "apm2-cli consensus transfer-leadership --to ID"
        description: "Request graceful leadership transfer"

    diagnostics:
      - command: "apm2-cli ledger verify-chain --namespace NS"
        description: "Verify hash chain integrity for a namespace"

      - command: "apm2-cli ledger diff --peer ADDR --namespace NS"
        description: "Compare local ledger with peer"

      - command: "apm2-cli consensus byzantine-evidence list"
        description: "List detected Byzantine faults"

    schema_management:
      - command: "apm2-cli schema list"
        description: "List registered schemas"

      - command: "apm2-cli schema register --proto-file FILE"
        description: "Register a new schema (requires consensus)"

      - command: "apm2-cli schema handshake --peer ADDR"
        description: "Perform schema handshake with a peer"
