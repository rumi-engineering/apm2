## Problem statement and target operating state

An agent-native software factory requires a **closed internal control loop** that transforms low-fidelity intent into high-fidelity specifications, executes those specifications as controlled code changes, verifies outcomes with independent gates (including Agent Acceptance Testing), and continuously improves its own guardrails by converting recurrent defects into preventive work. The primary problem is not producing documents or merging pull requests; the primary problem is engineering a **durable, auditable, recurrence-aware work substrate** in which planning, execution, verification, and refactoring are first-class, machine-checkable protocols rather than informal behaviors mediated by external systems. External platforms (GitHub, vendor consoles, ad-hoc scripts) may remain temporarily useful as projections or convenience surfaces, but correctness and auditability must not depend on them. The desired end state is an internal “forge” and “planner” where every meaningful state transition—plan approval, patch proposal, gate execution, findings raised/resolved, evidence publication, and merge acceptance—is represented as a **typed event** bound to **content-addressed artifacts**, enabling replay, attribution, and corrective governance.

In this operating state, “PRD completion” becomes a mid-lifecycle milestone, not a terminal state. A plan advances only when required gates have passed and required evidence exists, and it remains subject to post-implementation **hardening cycles**: refactor and simplification passes that integrate parallel workstreams, retire accidental complexity, and reduce recurrence risk. The system must also support operator audit and intervention while autonomy is immature: audit must be available as deterministic reconstruction from durable records, and interventions must themselves be recorded as governed decisions so that the factory can be corrected and later learn from human adjudication.

## Canonical terminology and definitions for shared understanding

The system benefits from fixed terms with precise meanings, because holonic networks degrade when protocols are described by narrative rather than by stable interfaces. The following definitions establish a vocabulary suitable for stable schemas, CLI commands, and reducers.

A **Work Substrate** is the combined set of (a) work-object specifications, (b) an append-only durable record of events over those objects, and (c) deterministic projections that compute current state and scheduling signals. The substrate is the only authoritative coordination plane across holons.

A **Work Object** is a typed entity with a stable canonical identifier and an explicit lifecycle. The foundational kinds are: **Plan** (intent/specification), **ChangeSet** (proposed modifications), **GateRun** (execution of a verification gate), **Finding** (structured defect report), **EvidenceBundle** (content-addressed proof artifacts + assertions + provenance), **Decision** (governed adjudication), and **Question** (explicit unresolved ambiguity with a stop condition). A Work Object is not merely a file or a ticket; it is a state machine with typed inputs and outputs.

A **Plan-of-Record** is the currently approved Plan specification snapshot bound by a content digest. Plan-of-Record is the binding surface for downstream refinement: tickets, changesets, and gates must trace back to an identified Plan-of-Record digest to prevent “drift by commentary.”

A **Spec Snapshot** is a deterministic representation of a work object’s specification content (YAML sections, referenced attachments, and schema versions) canonicalized and hashed. Spec Snapshots provide stable identity for “what exactly was reviewed,” independent of presentation.

A **ChangeSet** is the canonical unit of proposed work for implementation and refactoring. In the near term it may map to a git commit range; in the long term it must be representable as a patch set independent of branches or forge PR numbers. A ChangeSet is defined by input references (Plan-of-Record, dependencies), a patch representation, and produced artifacts.

A **Gate** is a formally defined verification protocol with a rubric and evidence contract; a **GateRun** is one execution instance of a Gate against a Plan or ChangeSet, producing a decision and a bounded set of Findings. AAT (Agent Acceptance Testing) is treated as a Gate, not as an informal test run.

A **Finding** is a structured report of nonconformance, with severity, category, location pointers, remediation requirements, and an associated **FindingSignature**. A FindingSignature is a deterministic identifier computed from normalized fields sufficient to cluster recurrence across workstreams.

A **Countermeasure** is a special class of planned work whose purpose is to prevent recurrence of a FindingSignature class by modifying guardrails (lint rules, templates, schema constraints, safe APIs, gate rubrics, or AAT hypothesis libraries). Countermeasures are validated by evidence of reduced recurrence.

A **Merge Receipt** is an internal acceptance record binding an approval decision to the exact input digests (Plan-of-Record digest, ChangeSet digest, GateRun digests) and the output repository state digest. It replaces “the PR merged” as the canonical acceptance fact.

These definitions are intentionally orthogonal to any specific external system. GitHub PRs, branch names, or vendor tool artifacts may appear as optional metadata within EvidenceBundles, but they must not be part of the primary identity or lifecycle semantics.

## Architectural doctrine: spec/state separation and event authority

The work substrate must enforce a strict separation between **specification content** and **workflow state**. Specification content consists of schema-validated YAML documents stored under a canonical directory (for example, `work/`), decomposed into small section files to support bounded context packages. Workflow state consists of lifecycle status, gate outcomes, episode provenance, and scheduling signals. Workflow state must be derived from a durable event record rather than inferred from filesystem scans or branch naming heuristics; inference introduces non-determinism, breaks replay, and makes parallelism fragile.

A sound implementation uses an append-only event log as the authoritative record, with deterministic reducers producing projections. In Rust, event payloads are most robust when modeled as versioned types serialized via `prost` (Protocol Buffers) to avoid ad-hoc JSON drift; large or variable artifacts should be stored out-of-line as content-addressed blobs referenced by event fields. Content addressing should use `blake3` for performance and simplicity. Event envelopes and critical receipts should be signed using `ed25519-dalek` (or a trait-based signing interface via `signature`) to support later crypto agility. Local durability can remain in SQLite using `rusqlite` with WAL enabled; a later migration to a replicated store becomes a backend change if the event API and reducers remain stable.

The near-term filesystem check-in remains acceptable as a frictionful but audit-friendly substrate. However, authored files must be treated as spec projections bound by digests. Any gate decision, review outcome, or merge acceptance must reference spec digests and artifact digests, not textual descriptions of “what was reviewed.” Canonicalization rules are required to stabilize digests: YAML parsing and re-emission should use `serde_yaml` with explicit ordering discipline, deterministic formatting, and an internal normalization step. Where schema validation is required, `schemars` can be used to generate JSON Schema and validate via a schema engine; alternatively, explicit validators with `thiserror`-structured diagnostics tend to be more explainable and safer in high-assurance domains.

## Internal forge model: changesets, patch sets, and merges without external dependency

Removing GitHub as a dependency requires treating “forge semantics” (proposal, review, iteration, acceptance) as native work semantics. The internal forge model should center on ChangeSets and GateRuns. ChangeSets must not be synonymous with branches. A branch is a transport artifact; it is not a durable identity. The internal canonical representation should support two encodings: a git-bound encoding (commit DAG references) for current operations and a patch-set encoding for future portability. Patch sets should be represented deterministically (for example, per-file content replacements or a normalized unified diff) and stored as artifacts with digests. The crate `gix` (gitoxide) provides a pure-Rust git substrate suitable for deterministic inspection and diff computation; `imara-diff` can be used for stable diff algorithms where required.

Merges must be governed, explicit, and auditable. A merge is not “git updated main”; it is a state transition that consumes a set of approved inputs (Plan-of-Record digest, ChangeSet digest, GateRun digests, Decision digests) and produces an output digest of repository state, yielding a Merge Receipt. The merge protocol should operate under a lease (exclusive authority) and emit a receipt event. This design enables later replacement of git or replacement of the forge UI without changing the semantics of acceptance, and it enables deterministic reconstruction of “what entered production and why.”

## Gate architecture: reviews, AAT, evidence contracts, and auditability

Verification gates must be treated as formal protocols with evidence contracts, not as comments or informal “LGTM” outcomes. A gate is defined by (a) a rubric specifying what to check, (b) an evidence schema specifying what must be produced to justify a decision, (c) a set of allowed tools and environments, and (d) stop conditions for pass/fail/escalate. GateRuns produce a decision plus findings, and must always publish an EvidenceBundle referencing raw tool outputs, digests of inputs, environment identity, policy versions, and any external call metadata. `tracing` should be used for structured instrumentation, but gate truth must not depend on logs; logs are supplementary. Evidence must be durable and content-addressed, with redaction and secret handling implemented via `secrecy` and `zeroize`. Where sensitive artifacts must be retained, authenticated encryption using `chacha20poly1305` (or an envelope scheme) should be used under a defined key-management story.

AAT should be treated as an independent gate with explicit hypothesis-driven evidence. Its purpose is not merely regression detection; its purpose is trust separation: independent verification by a holon with different context and different incentives reduces correlated failure modes. AAT GateRuns should emit findings that are structurally compatible with other gates so that recurrence analysis can unify across security/code/AAT defect classes. The evidence contract for AAT should privilege falsifiability: each hypothesis must identify expected signals, the method of observation, the environment, and the artifact outputs used to justify acceptance.

Human audit requires a deterministic “why-chain” from decision to evidence. Therefore, projections must support queries such as: “which findings blocked acceptance,” “which evidence justified override,” “which policy/rubric version was used,” and “which digests were reviewed.” The audit interface belongs in the internal CLI/TUI, not in ad-hoc scripts. An internal review UI can be deferred if the CLI provides complete causal reconstruction.

## Recurrence feedback loops: finding signatures, countermeasures, and guardrail evolution

Repeated security issues indicate failure of factory control, not merely local implementation defects. Fixing a single instance of a defect is a short-term actuator action; preventing recurrence is a control improvement. The system therefore requires a recurrence loop that is natively modeled in the substrate.

The recurrence loop begins with deterministic Finding normalization. Each gate must output Findings conforming to a shared schema, and each Finding must include enough canonical fields to compute a stable FindingSignature: category (for example, “secrets handling,” “capability leakage,” “unsafe deserialization”), a rule identifier where applicable, affected subsystem identifiers, language/runtime, and normalized location hints. Text embeddings may be useful as a secondary clustering aid, but stable recurrence metrics must not rely solely on probabilistic similarity; deterministic signatures enable reliable trend computation and enforcement actions.

Reducers then compute recurrence metrics: counts and rates of FindingSignatures over windows, time-to-resolution distributions, post-countermeasure recurrence deltas, and correlation with plan types or subsystems. When thresholds are exceeded, the scheduler creates Countermeasure work. Countermeasure specifications must be explicit about the preventive mechanism—lint rules, schema tightening, safe wrapper APIs, template changes, gate rubric updates, or new AAT hypothesis patterns—and must include verification evidence that the mechanism works on representative corpora. Gate evolution must itself be governed: new guardrails can introduce false positives or performance costs. Therefore, Countermeasure acceptance should require corpus replay evidence and an explicit rollback plan. Policy engines such as `cedar-policy` can encode authority and risk-tier rules so that high-impact guardrail changes require stronger gates.

This loop converts operator audit into system improvement: operator observation that “the same issue keeps appearing” becomes measurable recurrence data and triggers corrective work under governance, eventually reducing intervention frequency.

## Lifecycle governance beyond PRD: implementation, hardening cycles, and parallel stream integration

The lifecycle must explicitly include post-implementation hardening cycles because autonomous execution tends to accumulate local optimizations, scaffolding, and divergent abstractions under parallelism. Hardening cycles are not an admission of failure; they are a structured mechanism for entropy management. A standard lifecycle for non-trivial work includes: Plan drafted and refined to readiness, Plan approved (Plan-of-Record), initial ChangeSet implemented and verified, and then one or more **Hardening ChangeSets** scheduled as required by policy. Each hardening cycle runs the same gates as feature work, with emphasis on simplification, integration coherence, and guardrail reinforcement. The stopping condition for hardening is not subjective “cleanliness”; it is measurable reduction of complexity drivers, improved verification evidence, and resolved integration risks.

Parallel workstreams introduce structural risks: duplicated solutions, incompatible invariants, and unstable integration boundaries. Addressing this requires explicit graph semantics. Work Objects must maintain typed links: depends-on, blocks, supersedes, integrates-with, and implements. Projections should continuously identify collisions: multiple plans targeting the same subsystem, concurrent refactors touching the same interfaces, or conflicting constraints. An integration supervisor holon can then propose consolidation ChangeSets or require Decision objects that record an integration strategy. This prevents “integration by accident” and reduces late-stage conflict costs.

## Working guidelines and prescriptions for implementation in Rust

The following prescriptions are suitable as initial doctrine and can be revised as empirical evidence accumulates.

Work Object schemas shall be versioned, strict, and fail-closed. Parsing shall be performed with `serde` and `serde_yaml`, and schema validation shall provide localized diagnostics suitable for automated repair. Canonical IDs shall be generated and validated deterministically (`regex` or a dedicated parser), and references between objects shall be resolved and checked before gate scheduling. Directory layout shall privilege a single entrypoint (`manifest.yaml`) per object and small section files to enable bounded context packages and reduce accidental coupling.

All authoritative state transitions shall be emitted as typed events to the durable record, with artifact references bound by digests. Events shall be stored append-only in SQLite (`rusqlite`), and projections shall be computed by deterministic reducers. Event payload schemas shall be versioned (`prost`), and changes to event schemas shall be treated as migrations with replay testing. Correlation identifiers shall be propagated through episodes, tool calls, gate runs, and merges to enable causal reconstruction.

Gate execution shall be implemented as a controlled runner under the holon envelope, with explicit allowlists of tools and bounded budgets. Process execution may initially rely on network egress to vendor tools and external services; however, all external interactions shall be recorded as evidence metadata (endpoint class, request digests where safe, response digests, and timestamps) to support audit and future replacement. Sensitive material shall not be written to durable logs; secret handling shall use `secrecy` and `zeroize`, and durable sensitive artifacts shall be encrypted (`chacha20poly1305`) with an explicit key provenance mechanism.

ChangeSets shall be represented internally independent of forge primitives. Where git is used, repositories shall be inspected via pure-Rust libraries (`gix`) where feasible to reduce shell dependence and improve determinism. Patch representations shall be normalized prior to hashing to avoid digest churn from formatting variance. Merge acceptance shall produce a Merge Receipt binding approvals and gate outcomes to the exact output repository digest.

Recurrence reduction shall be treated as a first-class success metric for the factory. FindingSignature computation shall be deterministic and shared across gates. A recurrence reducer shall generate scheduling signals and enforce countermeasure creation thresholds. Countermeasure success shall be evaluated using before/after recurrence projections and corpus replay evidence, with rollback strategies defined for high-impact guardrail changes.

Operator audit shall be implemented as a first-class interface over projections. Audit queries shall reconstruct timelines and justification chains without relying on external platforms. Human interventions shall be explicit Decision objects and events, not silent out-of-band actions, enabling later system correction and learning.

This doctrine yields a work substrate that remains internally consistent under holonic constraints, supports network egress in the near term without making it an authority dependency, and provides a direct path to eliminating GitHub while increasing auditability, recurrence control, and robustness under parallel workstreams.
