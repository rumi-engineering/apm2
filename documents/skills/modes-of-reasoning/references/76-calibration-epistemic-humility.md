# Calibration and Epistemic Humility (Second-Order Uncertainty)

**Category:** Meta-Level and Reflective Modes

## What it is

Track how reliable your beliefs are (forecast scoring, error bars, backtesting).

## What it outputs

- Calibrated confidence
- Forecast accuracy metrics
- Improved priors
- Uncertainty estimates

## How it differs

First-order uncertainty is "what is true?"; calibration is "how good am I at knowing?" Knowing what you don't know.

## Best for

- Forecasting culture
- Risk reviews
- Decision reviews
- Learning from outcomes
- Expert assessment

## Common failure mode

Confusing confidence with competence; never measuring accuracy. Feeling confident doesn't mean being accurate.

## Related modes

- [Bayesian reasoning](11-bayesian-probabilistic.md) — provides the beliefs to calibrate
- [Reference-class reasoning](18-reference-class-outside-view.md) — base rates for calibration
- [Meta-reasoning](75-meta-reasoning.md) — reasoning about reasoning quality
