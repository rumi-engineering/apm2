{
  "schema": "cac.reasoning_mode.v1",
  "schema_version": "1.0.0",
  "kind": "reasoning.mode",
  "meta": {
    "stable_id": "dcp://apm2.agents/mor/mode/abductive@1",
    "classification": "PUBLIC",
    "created_at": "2025-02-01T00:00:00Z"
  },
  "payload": {
    "id": 13,
    "name": "abductive",
    "cat": "ampliative",
    "core": "Inference to the best explanation: generate hypotheses that would make observations unsurprising, then rank by scope, simplicity, coherence, testability, and mechanism. Introduces novel theoretical entities not directly observed. Terminates with candidate explanation plus discriminating tests—never with confirmed cause.",
    "out": [
      {"n": "observation_set", "d": "anomalous or surprising facts requiring explanation, stated without interpretation"},
      {"n": "hypothesis_pool", "d": ">=3 candidate explanations with fit rationale; must include mundane option"},
      {"n": "criteria_matrix", "d": "5-criteria scores (scope, simplicity, coherence, testability, mechanism) for each hypothesis"},
      {"n": "best_explanation", "d": "top hypothesis with explicit total score and runner-up delta"},
      {"n": "test_predictions", "d": ">=2 discriminating observations distinguishing top hypotheses"},
      {"n": "confidence_qualifier", "d": "uncertainty label (speculative/moderate/strong) with specific revision triggers"}
    ],
    "proc": [
      "ISOLATE: state observations without interpretation; if observations unclear, gather more before proceeding",
      "GENERATE: produce >=3 hypotheses including (a) mundane/boring cause, (b) structural/systemic cause, (c) exotic/novel cause",
      "SCORE: rate each hypothesis 1-3 on scope (explains how much?), simplicity (fewest entities?), coherence (fits background?), testability (falsifiable how?), mechanism (causal pathway clear?)",
      "RANK: select best by total score; if tie or <2 point gap, treat as underdetermined—need more data",
      "PREDICT: derive >=2 observations that would distinguish top hypothesis from runner-up; state expected vs actual",
      "QUALIFY: label confidence (speculative <9, moderate 9-12, strong >12); state what evidence would revise; identify next test",
      "GATE: if no hypothesis scores >9, stop and gather more observations; if top 2 tied, design discriminating experiment before proceeding"
    ],
    "check": [
      "explanandum stated as specific observations without causal language",
      ">=3 candidates generated including mundane option",
      "each hypothesis scored on all 5 criteria with numeric values",
      "best explanation selected with explicit total score",
      "runner-up identified with score delta stated",
      ">=2 distinguishing predictions for top hypotheses",
      "confidence labeled with numeric threshold rationale",
      "revision conditions stated (what evidence changes conclusion)",
      "next testing step identified with expected outcome",
      "output labeled 'candidate explanation' not 'cause' or 'confirmed'"
    ],
    "diff": {
      "inductive": "posits hidden causes from surprising observations vs generalizes patterns from confirming instances",
      "deductive": "introduces new explanatory content vs preserves truth already in premises",
      "diagnostic": "novel/unstructured problems requiring hypothesis invention vs structured fault trees with known failure modes",
      "causal-inference": "generates candidate causes vs tests/quantifies causal claims via intervention or conditioning",
      "likelihood-based": "generates hypotheses to explain vs scores P(evidence|hypothesis) for existing hypotheses",
      "case-based": "invents novel explanations for new phenomena vs retrieves/adapts known explanations from memory",
      "bayesian": "generates hypothesis set vs updates prior probabilities given evidence; use bayesian after abductive",
      "mechanistic": "proposes that mechanism exists vs traces step-by-step causal pathway; mechanistic validates abductive output",
      "sensemaking": "explains specific observations vs builds general interpretive frame; abductive is scoped, sensemaking is holistic"
    },
    "confusions": [
      {
        "trap": "using abductive when diagnostic applies",
        "symptom": "reinventing explanations for well-understood failure modes",
        "correction": "if fault model exists (e.g., network timeouts, OOM), use diagnostic mode with structured fault tree first; reserve abductive for genuinely novel anomalies"
      },
      {
        "trap": "treating abductive output as confirmed cause",
        "symptom": "skipping validation; acting on 'best explanation' without discriminating test",
        "correction": "abductive terminates with candidate + test predictions; hand off to causal-inference or experimental-design for confirmation"
      },
      {
        "trap": "conflating abductive with bayesian",
        "symptom": "trying to assign probabilities before hypothesis set is stable",
        "correction": "abductive generates hypotheses; bayesian updates probabilities on a fixed set; run abductive first, then bayesian"
      }
    ],
    "fail": {
      "mode": "story_bias",
      "desc": "Selecting narratively compelling explanations over evidence-supported ones; premature closure on vivid hypotheses",
      "signals": [
        "chose most narratively compelling hypothesis vs highest-scoring",
        "cannot articulate numeric criteria for why alternatives rejected",
        "favored explanation has clear villain, dramatic arc, or emotional resonance",
        "stopped at first plausible explanation without generating alternatives",
        "confidence exceeds what score and evidence warrant",
        "hypothesis is unfalsifiable or has no discriminating predictions"
      ],
      "mitigations": [
        {"m": "force >=3 hypotheses before any evaluation", "test": "hypothesis_pool.length >= 3"},
        {"m": "require mundane option in every pool", "test": "hypothesis_pool contains 'mundane' or 'boring' tagged option"},
        {"m": "score all 5 criteria numerically before ranking", "test": "criteria_matrix complete with no blanks"},
        {"m": "state runner-up and score delta explicitly", "test": "runner-up named with delta >= 0"},
        {"m": "articulate falsifying evidence for favored hypothesis", "test": "revision_triggers non-empty and specific"},
        {"m": "verify discriminating predictions differ between top 2", "test": "predictions[0] != predictions[1] on at least one observable"},
        {"m": "if favored hypothesis has villain/drama, add +1 skepticism and recheck scores", "test": "narrative_flag checked if villain present"},
        {"m": "time-box hypothesis generation to prevent anchoring on first idea", "test": "generation phase >= 2 min or >= 3 distinct sources consulted"}
      ]
    },
    "use": [
      "hypothesis generation in science (novel phenomena)",
      "incident triage and root cause analysis (unprecedented failures)",
      "medical differential diagnosis (atypical presentations)",
      "debugging from error observations (no obvious cause)",
      "detective/investigative work (crime reconstruction)",
      "anomaly investigation (security, fraud, system behavior)",
      "theory formation in research (explaining unexpected results)"
    ],
    "rel": [
      {"id": 9, "n": "inductive", "r": "pattern generalization; abductive posits cause, inductive generalizes pattern"},
      {"id": 1, "n": "deductive", "r": "truth-preserving inference; use deductive to derive predictions from abductive hypothesis"},
      {"id": 41, "n": "diagnostic", "r": "structured fault models; prefer diagnostic when fault tree known"},
      {"id": 37, "n": "causal-inference", "r": "tests causal hypotheses; validates abductive output via intervention"},
      {"id": 12, "n": "likelihood-based", "r": "scores hypotheses; use after abductive generates candidates"},
      {"id": 40, "n": "mechanistic", "r": "explains via mechanisms; validates abductive by tracing pathway"},
      {"id": 11, "n": "bayesian", "r": "updates probabilities; use after abductive fixes hypothesis set"},
      {"id": 15, "n": "case-based", "r": "retrieves known explanations; try case-based before abductive"},
      {"id": 69, "n": "experimental-design", "r": "designs discriminating tests for abductive predictions"},
      {"id": 63, "n": "sensemaking", "r": "holistic frame-building; abductive is narrower, observation-specific"}
    ],
    "ex": {
      "sit": "Production DB latency spikes daily at 2:47 PM, no deployment or traffic spike.",
      "steps": [
        "ISOLATE: 10x latency at 2:47 PM +/-2 min for 5 consecutive days; no code deploy, traffic flat",
        "GENERATE: (a) cron job I/O contention [mundane], (b) backup process [structural], (c) index rebuild [structural], (d) external retry storms [exotic]",
        "SCORE: backup=12/15 (scope:3, simplicity:3, coherence:2, testability:2, mechanism:2); cron=9/15; index=10/15; retry=7/15",
        "RANK: backup wins by 2 over index; cron 3 behind; retry distant",
        "PREDICT: backup->disk I/O spike at 2:47; cron->CPU spike; index->write lock contention; check I/O first",
        "QUALIFY: moderate confidence (score 12); revise if disk I/O normal at 2:47; next: add I/O monitoring"
      ],
      "insight": "backup hypothesis confirmed via I/O monitoring showing 95% disk util at 2:47; moved backup to 3 AM, latency resolved"
    },
    "micro_ex": {
      "sit": "Patient: fever + joint pain + rash after hiking trip; common infections ruled out",
      "hyp": ["Lyme disease [mundane-for-context]", "viral arthritis [structural]", "autoimmune flare [exotic]"],
      "scores": "Lyme=11 (exposure+classic triad), viral=8 (no viral prodrome), autoimmune=6 (no history)",
      "predict": "Lyme->positive serology + erythema migrans history; viral->self-limiting in 2wk",
      "next": "order Lyme serology; if negative, revisit viral hypothesis"
    },
    "quick_check": [
      "Did I state observations without causal language?",
      "Do I have >=3 hypotheses including a mundane one?",
      "Did I score all 5 criteria numerically?",
      "Is my best explanation labeled 'candidate' not 'cause'?",
      "Do I have a discriminating test that could falsify my top hypothesis?",
      "Did I state what evidence would make me revise?"
    ]
  }
}
