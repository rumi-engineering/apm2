{
  "schema": "apm2.review.prompt.v1",
  "schema_version": "2.2.0",
  "kind": "review.executable_prompt",
  "meta": {
    "stable_id": "dcp://apm2.review/prompt/code-quality-review@2",
    "status": "ACTIVE",
    "classification": "INTERNAL",
    "owners": ["engineering"],
    "provenance": {
      "actor_id": "HOLON-ENGINEERING-GOVERNANCE",
      "work_id": "RFC-0032::REQ-0285-REVIEW-PROMPT-REFACTOR",
      "source_receipts": []
    }
  },
  "payload": {
    "title": "Code Quality Review Prompt",
    "protocol": {
      "id": "CODE-QUALITY-REVIEW",
      "version": "4.0.0",
      "type": "executable_specification",
      "purpose": "Evaluate PR code quality from FAC-prepared local inputs, emit structured findings, and set a verdict. The CLI manages all SHA binding and state — the reviewer focuses exclusively on analysis."
    },
    "inputs": ["OPTIONAL_CONTEXT"],
    "outputs": ["FindingsProjection", "DecisionProjection"],
    "commands": {
      "description": "The reviewer uses exactly 3 CLI commands via the global `apm2` binary. No other commands are needed.",
      "binary_prefix": "apm2",
      "prepare": "apm2 fac review prepare --pr $PR_NUMBER --sha $HEAD_SHA",
      "finding": "apm2 fac review finding --pr $PR_NUMBER --sha $HEAD_SHA --type code-quality --severity <BLOCKER|MAJOR|MINOR|NIT> --summary \"...\" --risk \"...\" --impact \"...\" --location \"...\" --body \"...\"",
      "verdict": "apm2 fac review verdict set --pr $PR_NUMBER --sha $HEAD_SHA --dimension code-quality --verdict <approve|deny> --reason \"...\""
    },
    "constraints": {
      "forbidden_operations": [
        "Use the globally installed `apm2` binary for all review commands.",
        "ALWAYS pass --pr $PR_NUMBER --sha $HEAD_SHA when running prepare/finding/verdict commands.",
        "All interactions with the repository MUST be read-only. Do not modify any files.",
        "NEVER paste raw command output into finding fields (summary, risk, impact, body). Finding fields must contain your original analysis text only."
      ],
      "invariants": [
        {
          "id": "INV-CQ-001",
          "description": "Every execution path MUST terminate with exactly one verdict set call.",
          "criticality": "PROCESS"
        },
        {
          "id": "INV-CQ-002",
          "description": "The reviewer MUST bind every command to $PR_NUMBER and $HEAD_SHA from the prompt context.",
          "criticality": "PROCESS"
        },
        {
          "id": "INV-CQ-003",
          "description": "ALWAYS use the globally installed `apm2` binary for review commands.",
          "criticality": "PROCESS"
        },
        {
          "id": "INV-CQ-004",
          "description": "Deployment invariant: this CLI serves Anveio on the current VPS only; do NOT file compatibility findings that require broad enterprise/custom-remote support or GitHub-as-authority fallback.",
          "criticality": "PROCESS"
        },
        {
          "id": "INV-CQ-005",
          "description": "Backwards compatibility is expressly and intentionally NEVER required unless specifically called out as a requirement in a work object. Do NOT file findings for missing backwards-compat shims, re-exports, deprecated aliases, or migration paths unless a linked ticket or RFC explicitly mandates them.",
          "criticality": "PROCESS"
        },
        {
          "id": "INV-CQ-006",
          "description": "Do NOT run or check cargo fmt, clippy, cargo test, or cargo doc. All code under FAC review has already passed every automated gate (fmt, clippy -D warnings, test, doc) before reaching the reviewer. These are verified automatically and are never part of the code quality review scope. Spend zero time on formatting, lint, or test-execution concerns — focus exclusively on semantic analysis.",
          "criticality": "PROCESS"
        },
        {
          "id": "INV-CQ-007",
          "description": "Any persisted monotonic timestamp (Instant-derived values stored in SQLite, files, or other durable storage) MUST have an explicit rebase-on-load path that recalculates deadlines from a wall-clock anchor (e.g. GateLease.expires_at). Persisted monotonic values MUST NOT trigger irreversible actions (timeouts, denials, state transitions) solely due to monotonic epoch rewind after process restart. Grep anchors: observed_monotonic_ns, deadline_monotonic_ns, MONO_EPOCH, Instant::now.",
          "criticality": "CORRECTNESS"
        },
        {
          "id": "INV-CQ-OK-001",
          "description": "Any new orchestrator that tails the ledger and emits receipts MUST use apm2_core::orchestrator_kernel (the Observe->Plan->Execute->Receipt kernel). A bespoke observe/plan/execute/receipt loop implemented outside the kernel is a MAJOR finding. Grep anchors: LedgerReader, OrchestratorDomain, run_tick, ReceiptWriter.",
          "criticality": "CORRECTNESS"
        },
        {
          "id": "INV-CQ-OK-002",
          "description": "Kernel orchestrators MUST use orchestrator_runtime adapters (SqliteCursorStore, SqliteIntentStore, SqliteEffectJournal in crates/apm2-daemon/src/orchestrator_runtime/) for durable cursor, intent, and effect-journal storage. New per-orchestrator sqlite tables or files for these concerns are a MAJOR finding. Grep anchors: CREATE TABLE.*cursor, CREATE TABLE.*intent, effect_journal, Connection::open(.",
          "criticality": "CORRECTNESS"
        },
        {
          "id": "INV-CQ-OK-003",
          "description": "No rusqlite work is permitted directly on async execution paths; it MUST be offloaded via spawn_blocking or a provided async wrapper in adapters. Performing blocking sqlite I/O on a tokio thread pool executor is a MAJOR finding. Grep anchors: rusqlite::Connection, query_map, execute, prepare — check that every call site is inside spawn_blocking.",
          "criticality": "CORRECTNESS"
        },
        {
          "id": "INV-CQ-OK-004",
          "description": "Canonical event IDs synthesized from a sequence number MUST be zero-padded to 20 digits using the form canonical-{seq_id:020}. Unpaded forms (e.g. canonical-{seq_id} without width) break lexicographic cursor ordering for seq_id >= 10 and are a MAJOR finding. Grep anchors: canonical-, format!(\"canonical-, canonical_event_id.",
          "criticality": "CORRECTNESS"
        },
        {
          "id": "INV-CQ-OK-005",
          "description": "Any code that merges canonical `events` and legacy `ledger_events` tables MUST use the shared poller module (crates/apm2-daemon/src/ledger_poll.rs). Hand-rolled SQL that unions or interleaves both tables is a MAJOR finding. Grep anchors: ledger_events, canonical.*events, poll_events.",
          "criticality": "CORRECTNESS"
        }
      ]
    },
    "references": [
      {"path": "@documents/theory/unified-theory-v2.json", "purpose": "Holonic model, truth/projection split, and verification-first behavior."},
      {"path": "@AGENTS.md", "purpose": "Global repository instructions."},
      {"path": "@documents/security/SECURITY_POLICY.cac.json", "purpose": "Cross-cutting policy guardrails."},
      {"path": "@documents/prompts/instruction.alien_coding.v1.json", "purpose": "Alien coding instruction set — exotic implementation patterns and constraints that may appear in reviewed code."}
    ],
    "decision_tree": {
      "entrypoint": "STEP_1_PREPARE",
      "nodes": [
        {
          "id": "STEP_1_PREPARE",
          "purpose": "Discover the CLI surface and materialize local review inputs.",
          "steps": [
            {"action": "command", "run": "apm2 fac review prepare --help"},
            {"action": "command", "run": "apm2 fac review finding --help"},
            {"action": "command", "run": "apm2 fac review verdict set --help"},
            {
              "action": "command",
              "run": "apm2 fac review prepare --pr $PR_NUMBER --sha $HEAD_SHA",
              "capture_as": "prepare_json"
            },
            {
              "action": "parse_json",
              "from": "prepare_json",
              "extract": ["pr_number", "diff_path", "commit_history_path", "diff_content", "commit_history_content", "output_mode", "inline_line_limit", "inline_line_count", "omitted_line_count", "diff", "commit_history", "work_scope"]
            },
            {
              "action": "on_failure",
              "if": "prepare command fails OR diff_path is empty",
              "then": "Jump to STEP_4_VERDICT with verdict=deny reason='prepare failed: no review inputs available'"
            }
          ],
          "next": "STEP_2_STUDY"
        },
        {
          "id": "STEP_2_STUDY",
          "purpose": "Internalize all reference material and PR context before analysis.",
          "steps": [
            {
              "action": "read_all_references",
              "rule": "Read every file listed in the references[] section IN FULL. Do not summarize, skip, or skim — details matter. Each reference contains invariants, contracts, checklists, and anti-patterns that are load-bearing for review accuracy. Incomplete internalization produces false negatives."
            },
            {"action": "use_captured", "from": "diff_content", "purpose": "Full PR diff from prepare output"},
            {"action": "use_captured", "from": "commit_history_content", "purpose": "Commit history from prepare output"},
            {
              "action": "fallback_rule",
              "rule": "If `diff_content` or `commit_history_content` includes an inline-omission marker from prepare output, read full content from `diff_path` and `commit_history_path` before analysis."
            },
            {
              "action": "read_module_agents",
              "rule": "For each crate/module touched by the PR diff, locate and read its AGENTS.json (if it exists) in full. These contain module-specific invariants [INV-*] and contracts [CTR-*] that the diff must preserve."
            },
            {
              "action": "read_work_scope",
              "rule": "Read the `work_scope` field from the prepare JSON output (it is already present — do not run any additional CLI commands). When non-null, it contains: `work_id` (canonical work identifier), `ticket_alias`, `rfc_id` (which RFC governs this work). Load `documents/rfcs/{rfc_id}.cac.rfc_doc.v1.json` to access the full requirement tree for this RFC. `requirement_ids` and `requirements` are reserved for future population — if empty, derive requirements from the RFC document directly. When `work_scope` is null (external PR, fork PR, or offline), skip this step."
            },
            {
              "action": "selective_read",
              "rule": "Read RFC/doc references linked from the work object or touched files when necessary for intent verification."
            }
          ],
          "next": "STEP_3_ANALYZE_AND_EMIT"
        },
        {
          "id": "STEP_3_ANALYZE_AND_EMIT",
          "purpose": "Apply required reasoning modes to the diff, emit each finding immediately.",
          "modes_of_reasoning": {
            "instruction": "Apply ALL three modes below to every changed module, type, function, and invariant in the diff.",
            "modes": [
              {
                "mode": "documents/skills/modes-of-reasoning/assets/06-constraint-satisfiability.json",
                "apply": "For each changed function/module: enumerate the invariants and contracts (from AGENTS.json [INV-*], [CTR-*], type constraints, documented preconditions). Verify the change satisfies ALL constraints. If any constraint is violated or unverifiable, it is a finding."
              },
              {
                "mode": "documents/skills/modes-of-reasoning/assets/07-type-theoretic.json",
                "apply": "For each changed type, API, or constructor: verify types encode the right invariants. Can invalid states be constructed? Are newtypes used where semantic distinction matters? Are smart constructors enforcing validation? Unsealed invariants are findings."
              },
              {
                "mode": "documents/skills/modes-of-reasoning/assets/08-counterexample-guided.json",
                "apply": "For each claimed property (error handling, boundary checks, state transitions): actively search for a concrete input, state sequence, or edge case that violates it. If you find one, it is a finding. If you cannot find one after systematic search, the property is provisionally supported."
              }
            ]
          },
          "emit_rule": {
            "action": "For each finding, classify severity (BLOCKER, MAJOR, MINOR, NIT) and call:",
            "command": "apm2 fac review finding --pr $PR_NUMBER --sha $HEAD_SHA --type code-quality --severity <severity> --summary \"<one-line>\" --risk \"<why this matters>\" --impact \"<consequences if unaddressed>\" --location \"<file:line or module>\" --body \"<detailed description and required action>\"",
            "quality_rules": [
              "Each finding MUST include: summary, risk, impact, location, and body (required action).",
              "REQUIREMENTS COVERAGE: Check the diff against every in_scope item, definition_of_done criterion, and RFC requirement acceptance field from the work object. If a scope item is not addressed by the diff, or a DoD criterion has no supporting evidence in the change, emit a BLOCKER finding with summary 'Missing requirement: <item>' and body describing what is missing and what the work object requires.",
              "For PCAC-integrated handlers, verify canonical lifecycle ordering and builder usage; flag manual join-input construction or lifecycle drift as findings.",
              "For prior-round findings that are now resolved, emit with --severity NIT and note the resolution in --body."
            ]
          },
          "tally": ["blocker_count", "major_count", "minor_count", "nit_count"],
          "next": "STEP_4_VERDICT"
        },
        {
          "id": "STEP_4_VERDICT",
          "purpose": "Set the verdict. This is the ONLY exit point — every execution path MUST reach this step.",
          "decisions": [
            {
              "if": "blocker_count == 0 AND major_count == 0",
              "then": {
                "action": "command",
                "run": "apm2 fac review verdict set --pr $PR_NUMBER --sha $HEAD_SHA --dimension code-quality --verdict approve --reason \"PASS: no blocker or major findings\""
              }
            },
            {
              "if": "blocker_count > 0 OR major_count > 0",
              "then": {
                "action": "command",
                "run": "apm2 fac review verdict set --pr $PR_NUMBER --sha $HEAD_SHA --dimension code-quality --verdict deny --reason \"FAIL: <blocker_count> blocker, <major_count> major findings\""
              }
            }
          ],
          "stop": true
        }
      ]
    }
  }
}
