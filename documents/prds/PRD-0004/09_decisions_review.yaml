prd_decisions_review:
  schema_version: "2026-01-23"
  template_version: "2026-01-23"
  decisions:
    - id: "DEC-0001"
      title: "Ledger as source of truth (not GitHub)"
      status: "ACCEPTED"
      context: |
        The APM2 Work Substrate requires durable, auditable, and deterministic work state management.
        In conventional workflows, external forge platforms (GitHub, GitLab) serve as the authoritative
        source of work status, reviews, and approvals. This creates fragility when the forge is
        unavailable, makes replay/audit dependent on external API semantics, and couples work semantics
        to vendor-specific primitives. For agent-native operations with holonic coordination, work state
        must be queryable, reproducible, and verifiable from an internal append-only record.
      decision: |
        The internal ledger is the sole authoritative source for all work state. All work lifecycle
        transitions (Plan creation, ChangeSet submission, gate execution, findings, approvals, merges)
        are recorded as typed events in the ledger. GitHub and other external forges are treated as
        sync adapters that project ledger state outward for human visibility and external CI integration.
        Sync failures do not block internal work progression. All queries about work status, history,
        gate outcomes, and traceability are answered from deterministic ledger projections (reducers),
        never from external forge APIs.
      rationale: |
        This design provides several critical properties: (1) Work state is reproducible by replaying
        ledger events, enabling audit and debugging; (2) Internal operations proceed regardless of
        external forge availability; (3) Agents operate through stable internal APIs without knowledge
        of external forge semantics; (4) The system can migrate to different forge platforms or internal
        UIs without changing work semantics; (5) All state transitions are cryptographically traceable
        to actor identity and episode context. This aligns with Principia Holonica's requirement for
        bounded holonic episodes with deterministic execution and explicit provenance.
      alternatives_considered:
        - alternative: "Use GitHub as source of truth with local caching"
          rejected_because: |
            Caching GitHub state creates consistency challenges (cache invalidation, synchronization
            races), makes offline operation fragile, and couples work semantics to GitHub's data model.
            Audit and replay would require external API access and be subject to GitHub's retention
            and availability policies.
        - alternative: "Dual-write to ledger and GitHub with eventual consistency"
          rejected_because: |
            Dual-write patterns are notoriously difficult to implement correctly and introduce split-brain
            scenarios when systems disagree. Determining the "true" state becomes ambiguous, and
            conflict resolution logic becomes a maintenance burden. This violates the requirement for
            deterministic state reconstruction.
        - alternative: "Hybrid model where GitHub is authoritative for some state classes"
          rejected_because: |
            Splitting authority between systems creates cognitive overhead, introduces subtle bugs
            when boundaries are unclear, and undermines the deterministic replay property. It also
            prevents clean migration to alternative forge platforms.
      consequences:
        positive:
          - "Work status queries are fast (<100ms) and always available from local projections"
          - "Complete audit trail from ledger events enables deterministic why-chain reconstruction"
          - "System can operate fully offline; GitHub sync is optional and asynchronous"
          - "Migration to alternative forges or internal UIs requires only adapter changes"
          - "All work state is cryptographically verifiable with actor attribution"
        negative:
          - "Requires building and maintaining GitHub sync adapter for external visibility"
          - "Human operators must use internal CLI/TUI rather than relying solely on GitHub UI"
          - "Sync adapter failures require monitoring and retry logic"
          - "External collaborators (non-agent contributors) may experience friction with dual-system model"
        mitigations:
          - "GitHub sync adapter implements idempotent projection with comprehensive error handling"
          - "Operator console provides rich audit/timeline/stats commands to reduce reliance on GitHub UI"
          - "Sync failures emit observable events for monitoring; retry with exponential backoff"
          - "Clear documentation and onboarding materials for human contributors"
      related_requirements:
        - "REQ-0005"  # Ledger as authoritative work state
        - "REQ-0006"  # Deterministic projections from ledger events
        - "REQ-0015"  # GitHub sync adapter projects ledger state
        - "REQ-0016"  # Internal operations proceed without GitHub
        - "REQ-0017"  # Work state queries from ledger projections
      related_goals:
        - "G-0002"  # All work state lives in ledger and is projectable via reducers
      related_constraints:
        - "CNS-0001"  # Forge API isolation
        - "CNS-0002"  # Ledger authority

    - id: "DEC-0002"
      title: "FindingSignature design for recurrence tracking"
      status: "ACCEPTED"
      context: |
        Agent-generated code can exhibit recurring defect patterns (e.g., improper secrets handling,
        unsafe deserialization, capability leakage). Fixing individual instances provides immediate
        remediation but does not prevent the same issue class from reappearing in parallel workstreams
        or future work. Without systematic recurrence detection, the factory accumulates technical debt
        and wastes review/remediation effort on the same issue types repeatedly. To enable systematic
        improvement, the system must detect when the same logical defect appears across different
        files, commits, or agents, and trigger preventive countermeasure work (guardrail improvements,
        lint rules, template changes, safe API wrappers).
      decision: |
        All findings produced by gates (AAT, security, code quality) must include a deterministic
        FindingSignature computed from canonical fields: category (e.g., "secrets_handling",
        "capability_leakage"), rule_id, language, api_surface, and a snippet_fingerprint (blake3 hash
        of normalized code snippet with whitespace removed and variables anonymized). The same logical
        issue in different locations must produce identical signatures. A RecurrenceReducer projection
        tracks finding counts and rates by signature, and when thresholds are exceeded, automatically
        creates Countermeasure work items proposing guardrail improvements. Countermeasure effectiveness
        is measured as reduction in recurrence rate post-deployment.
      rationale: |
        Deterministic signatures enable O(1) recurrence lookup and reliable clustering across the entire
        factory lifetime. Using normalized snippets and canonical fields ensures that equivalent issues
        are recognized regardless of variable names, formatting, or file locations. This design supports
        data-driven factory improvement: recurring issues become measurable signals, thresholds trigger
        automated countermeasure creation, and effectiveness can be validated empirically. It aligns
        with the doctrine that "repeated security issues indicate failure of factory control, not merely
        local implementation defects."
      alternatives_considered:
        - alternative: "Use LLM embeddings for semantic similarity clustering"
          rejected_because: |
            Embeddings are probabilistic and non-deterministic across model versions, making recurrence
            counts unstable and audit trails non-reproducible. Deterministic signatures are required for
            reliable metrics, threshold enforcement, and regulatory compliance. Embeddings may serve as
            a secondary clustering aid but cannot be the primary mechanism.
        - alternative: "Cluster findings manually via human review"
          rejected_because: |
            Manual clustering does not scale with agent-native velocity, introduces subjective variance,
            and defeats the purpose of systematic feedback loops. Automation is required to operate at
            factory scale with consistent criteria.
        - alternative: "Use only rule_id for recurrence tracking"
          rejected_because: |
            Rule IDs alone are too coarse-grained; they conflate different manifestations of the same
            rule violation. For example, "secrets in environment variables" vs "secrets in config files"
            may both trigger the same lint rule but require different countermeasures. Snippet-level
            fingerprinting provides the right granularity for targeted improvements.
      consequences:
        positive:
          - "Recurrence detection is deterministic and reproducible across system replays"
          - "O(1) signature lookup enables real-time recurrence queries and dashboards"
          - "Same logical issue is recognized across files, commits, agents, and time"
          - "Countermeasure creation is automated when recurrence exceeds thresholds"
          - "Effectiveness metrics enable data-driven factory improvement"
        negative:
          - "Requires careful normalization to avoid false positives/negatives"
          - "Snippet anonymization may over-cluster unrelated issues with similar structure"
          - "Signature schema evolution requires migration strategy"
        mitigations:
          - "Property tests verify signature determinism across equivalent code patterns"
          - "Signature schema is versioned; signature_version field enables gradual migration"
          - "Normalization rules are explicit and documented; edge cases trigger refinement"
          - "Human review of high-recurrence signatures validates clustering quality"
      related_requirements:
        - "REQ-0012"  # Deterministic finding signatures for clustering
        - "REQ-0013"  # Recurrence tracking by signature
        - "REQ-0014"  # Countermeasure effectiveness tracking
      related_goals:
        - "G-0004"  # Structured feedback enabling systematic self-improvement
      related_constraints:
        - "CNS-0003"  # Finding determinism

    - id: "DEC-0003"
      title: "Gate execution model (bounded holonic episodes)"
      status: "ACCEPTED"
      context: |
        Verification gates (AAT, security review, code quality checks) are critical control points that
        determine whether work advances. In conventional CI/CD, gate execution is often ad-hoc, unbounded,
        and lacks provenance: scripts run with implicit timeouts, produce unstructured logs, and provide
        no clear evidence trail. For agent-native operations, gates must be reproducible, auditable, and
        resource-controlled. Unbounded gate execution creates resource exhaustion risks, unpredictable
        costs, and makes it impossible to reason about system behavior. Gates must also support
        independent parallel execution to avoid serialization bottlenecks in multi-agent workflows.
      decision: |
        Each gate (AAT, security, code quality) executes as a bounded holonic episode with defined
        budget constraints (token limit, time limit, max_episode count). Gates implement a Gate trait
        with gate_type(), required_evidence_categories(), and run() methods. GateRunner orchestrates
        execution, creating an EpisodeContext with work_id, lease_id, and budget limits. Episode
        execution terminates gracefully (not hard-kill) when budgets are exhausted. GateRunStarted and
        GateRunCompleted events are emitted to the ledger with provenance, budget consumption, and
        evidence bundle references. Gates produce typed Findings and EvidenceBundles rather than
        unstructured logs. Multiple independent gates can run in parallel; dependencies are expressed
        explicitly in gate definitions.
      rationale: |
        Bounded episodes provide predictable resource consumption, enable cost control, and support
        deterministic replay. The Gate trait establishes a stable interface for new gate implementations,
        and explicit evidence contracts enable verification of gate correctness. Emitting GateRunStarted/
        Completed events to the ledger creates a complete audit trail: which gate ran, when, with what
        budget, consuming what resources, producing what findings and evidence. This aligns with
        Principia Holonica Axiom II (Boundary Integrity) and Axiom III (Autonomous Decision Authority):
        each gate operates within a bounded context, makes decisions using explicit criteria, and
        produces verifiable outputs.
      alternatives_considered:
        - alternative: "Run gates as unbounded background jobs"
          rejected_because: |
            Unbounded execution creates runaway cost risks, makes system behavior unpredictable, and
            prevents resource scheduling. Without budgets, gates could consume arbitrary resources,
            violating holonic boundary integrity.
        - alternative: "Use hard timeouts with process termination"
          rejected_because: |
            Hard kills prevent graceful shutdown, make it impossible to emit partial results or evidence,
            and create audit gaps. Graceful termination enables gates to report progress and budget
            exhaustion reasons.
        - alternative: "Embed gate logic directly in work orchestration code"
          rejected_because: |
            Tight coupling prevents independent gate evolution, makes it difficult to add new gates,
            and violates separation of concerns. The Gate trait provides a stable extension point for
            new verification strategies without changing orchestration logic.
      consequences:
        positive:
          - "Gate execution is predictable, reproducible, and auditable from ledger events"
          - "Resource consumption is bounded and trackable via budget metrics"
          - "New gates can be added by implementing the Gate trait without changing orchestration"
          - "Independent gates can run in parallel without artificial serialization"
          - "Evidence bundles provide complete provenance for gate decisions"
        negative:
          - "Budget exhaustion may prevent gate completion; requires retry/escalation logic"
          - "Gate trait imposes implementation overhead for simple checks"
          - "Budget tuning requires empirical data and iterative refinement"
        mitigations:
          - "Budget exhaustion triggers escalation event and human review request"
          - "Simple gates can use minimal implementations with defaults"
          - "Budget recommendations are provided based on historical data and gate complexity"
          - "Gates emit progress events enabling adaptive budget adjustment"
      related_requirements:
        - "REQ-0008"  # Gates execute as bounded holonic episodes
        - "REQ-0009"  # Gates produce evidence bundles
        - "REQ-0010"  # Evidence bundles are content-addressed
      related_goals:
        - "G-0003"  # Reviews and gates operate as internal holonic episodes
      related_constraints:
        - "CNS-0005"  # Evidence completeness
      related_invariants:
        - "INV-0006"  # Deterministic adjudication

    - id: "DEC-0004"
      title: "Channel class design for forge adapters"
      status: "ACCEPTED"
      context: |
        The GitHub sync adapter must interact with external APIs to project ledger state, import CI
        results, and maintain external visibility. However, treating all external interactions uniformly
        creates security, performance, and reliability risks. Different interaction patterns have
        different trust requirements, bandwidth characteristics, and failure modes. For example,
        repository enumeration during setup is low-trust and infrequent, while PR synchronization is
        high-trust and high-frequency. Without explicit channel classes, rate limits become hard to
        reason about, security boundaries blur, and operational visibility suffers. The design must
        align with Principia Holonica Axiom VI (Selective Permeability): "Not all connections are equal.
        A holon maintains distinct channel classes... Each channel class has different budgets, retention,
        and allowed semantics."
      decision: |
        The GitHub sync adapter implements four distinct channel classes: (1) Discovery (low-trust,
        low-bandwidth): repository enumeration, rate limit checks, authentication verification;
        (2) Handshake (medium-trust, low-bandwidth): identity exchange, permission queries, capability
        discovery; (3) Work (high-trust, medium-bandwidth): PR/issue synchronization, status updates,
        merge operations, with sub-channels for pr_sync, issue_sync, and ci_result_import; (4) Evidence
        (high-trust, high-bandwidth): hash publication, artifact verification, state reconciliation,
        audit log export. Each channel class defines allowed operations, prohibited semantics, request
        budgets (requests/hour, max payload), and retention policies (log retention, cache TTL). The
        adapter enforces these constraints using token bucket rate limiting with exponential backoff
        and circuit breaker patterns.
      rationale: |
        Channel classes provide explicit reasoning about trust, performance, and failure modes. Discovery
        and handshake channels are transient and low-trust, enabling safe exploration without risking
        state corruption. Work channels are contract-bound (each PR maps to exactly one WorkID), ensuring
        traceability and preventing orphaned or duplicate projections. Evidence channels prioritize
        integrity and auditability, with hash verification and append-only semantics. Distinct budgets
        prevent bulk sync from starving control operations. This design enables safe multi-forge support
        in the future: each forge adapter implements the same channel classes with platform-specific
        details. It also provides operational visibility: channel-level metrics reveal bottlenecks,
        errors, and budget exhaustion patterns.
      alternatives_considered:
        - alternative: "Uniform API client with no channel separation"
          rejected_because: |
            Uniform clients conflate different trust and performance requirements, making it impossible
            to apply appropriate rate limits, retry strategies, or security controls. A single failure
            mode affects all interaction types, reducing resilience.
        - alternative: "Per-operation rate limiting without channel abstraction"
          rejected_because: |
            Operation-level limits are too fine-grained and difficult to configure. Channel classes
            provide the right level of abstraction for reasoning about system behavior and tuning
            policies. They also make cross-forge patterns explicit and reusable.
        - alternative: "No formal budgets; rely on GitHub API rate limits"
          rejected_because: |
            Relying on external rate limits creates unpredictable behavior, makes it difficult to
            prevent resource exhaustion, and couples system behavior to vendor policies. Internal
            budgets provide deterministic control and enable proactive scheduling.
      consequences:
        positive:
          - "Explicit channel classes make trust, performance, and failure modes explicit"
          - "Rate limiting prevents bulk sync from starving control operations"
          - "Per-channel metrics enable operational visibility and bottleneck diagnosis"
          - "Channel semantics enforce traceability (WorkID binding) and integrity (hash verification)"
          - "Design is portable across forge platforms with similar channel class implementations"
        negative:
          - "Channel class enforcement adds implementation complexity"
          - "Budget tuning requires empirical data and iterative refinement"
          - "Circuit breaker logic introduces additional operational surface area"
        mitigations:
          - "Channel class definitions are explicit and documented in solution overview"
          - "Budget recommendations are provided based on typical usage patterns"
          - "Circuit breaker states are observable via metrics and CLI commands"
          - "Adapter tests verify channel class constraints and budget enforcement"
      related_requirements:
        - "REQ-0015"  # GitHub sync adapter projects ledger state
        - "REQ-0016"  # Internal operations proceed without GitHub
        - "REQ-0017"  # Work state queries from ledger projections
      related_goals:
        - "G-0002"  # External forges are sync adapters, not sources of truth
      related_constraints:
        - "CNS-0001"  # Forge API isolation
      related_doctrine:
        - "Principia Holonica Axiom VI: Selective Permeability"
  gate_reviews:
    - gate_id: "GATE-PRD-SECURITY"
      status: "PENDING"
      evidence_ids: []
    - gate_id: "GATE-PRD-PRODUCT"
      status: "PENDING"
      evidence_ids: []
  waivers: []
